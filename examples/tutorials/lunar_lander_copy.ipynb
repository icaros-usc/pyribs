{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/icaros-usc/pyribs/blob/master/examples/tutorials/lunar_lander.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lunar Lander Tutorial\n",
    "\n",
    "In this tutorial, we'll walk through how to use the `ribs` implementaiton of MAP-Elites to solve OpenAI Gym's Lunar Lander problem. Specifically, the environment we'll be using is `LunarLander-v2`.\n",
    "\n",
    "## Overview\n",
    "\n",
    "OpenAI Gym is a common toolkit used to test and evaluate reinforcement learning algorithms. It provides various environments/problems for algorithms to solve. In our case, we'll be trying to get a lunar lander to land successfully on the moon within a certain target area. To find out more, visit [OpenAI's page](https://gym.openai.com/envs/LunarLander-v2/) on this environment. Using MAP-Elites, we'll discover and visualize a diverse range of solutions to this problem.\n",
    "\n",
    "If you're unfamiliar with the MAP-Elites algorithm, take a look at [this paper](https://arxiv.org/abs/1504.04909) which introduces the algorithm that we use in this notebook. It should be noted that while the algorithm in the paper minimizes performance, the `ribs` implementation maximizes performance instead. Additionally, instead of generating random solutions in the initial stage of MAP-Elites, our implementation samples from a Gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Here we'll retrieve all of our dependencies. `dask` is a library that allows parallelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ribs[examples] in /Users/yaya/Documents/USC/Research/ICAROS/pyribs (0.0.0)\n",
      "\u001b[33m  WARNING: ribs 0.0.0 does not provide the extra 'examples'\u001b[0m\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/yaya/anaconda/lib/python3.7/site-packages (from ribs[examples]) (1.18.1)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /Users/yaya/anaconda/lib/python3.7/site-packages (from ribs[examples]) (1.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/yaya/anaconda/lib/python3.7/site-packages (from pandas>=1.0.0->ribs[examples]) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/yaya/anaconda/lib/python3.7/site-packages (from pandas>=1.0.0->ribs[examples]) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yaya/anaconda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=1.0.0->ribs[examples]) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/yaya/anaconda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install ribs[examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "from ribs.archives import GridArchive\n",
    "from ribs.optimizers import Optimizer\n",
    "from ribs.emitters import GaussianEmitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lunar Lander Simulation\n",
    "\n",
    "First, let's write a `simulate()` function to run a prospective solution in the `LunarLander-v2` environment. We'll get to how we generate these prospective solutions later.\n",
    "\n",
    "`simulate()` takes in a prospective solution (i.e. policy) and uses this policy to make the Lunar Lander take actions in the environment. After the simulation is completed, `simulate()` returns several things. It returns the sum of the rewards of all actions taken in the environment (i.e. `total_reward`), the final state of the environment (i.e. `obs`), and the number of timesteps it took for the simulation to run to completion (i.e. `timesteps`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(\n",
    "    env_name: str,\n",
    "    model,\n",
    "    seed: int = None,\n",
    "    render: bool = False,\n",
    "    delay: int = 10,\n",
    "):\n",
    "    \"\"\"Runs the model in the env and returns the cumulative reward.\n",
    "    Add the `seed` argument to initialize the environment from the given seed\n",
    "    (this makes the environment the same between runs).\n",
    "    The model is just a linear model from input to output with softmax, so it\n",
    "    is represented by a single (action_dim, obs_dim) matrix.\n",
    "    Add an integer delay to wait `delay` ms between timesteps.\n",
    "    \"\"\"\n",
    "    total_reward = 0.0\n",
    "    env = gym.make(env_name)\n",
    "\n",
    "    # Seeding the environment before each reset ensures that our simulations are\n",
    "    # deterministic. We cannot vary the environment between the runs because\n",
    "    # that would confuse CMA-ES. See\n",
    "    # https://github.com/openai/gym/blob/master/gym/envs/box2d/lunar_lander.py#L115\n",
    "    # for the implementation of seed() for LunarLander.\n",
    "    if seed is not None:\n",
    "        env.seed(seed)\n",
    "    obs = env.reset()\n",
    "\n",
    "    timesteps = 0\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        # If render is set to True, then a video will appear showing the Lunar Lander\n",
    "        # taking actions in the environment.\n",
    "        if render:\n",
    "            env.render()\n",
    "            if delay is not None:\n",
    "                time.sleep(delay / 1000)\n",
    "\n",
    "        # Deterministic. Here is the action. Multiply observation by policy. Model is the policy and obs is state\n",
    "        action = np.argmax(model @ obs)  \n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        timesteps += 1\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    return total_reward, obs[0], timesteps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAP-Elites with `ribs`\n",
    "\n",
    "`ribs` makes it easy to run the MAP-Elites algorithm to solve reinforcement learning problems. Let's run through  some basics before we apply `ribs` to solve the Lunar Lander problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridArchive\n",
    "\n",
    "`GridArchive` is a container class used to house the solutions generated by MAP-Elites. It is our map of elites. When constructing a `GridArchive`, you can specify its dimensions, the range of valid values in our behaviour space, and certain configuration settings. These configuration settings include a seed for getting random solutions in the archive to mutate, which is essential to MAP-Elites, and a batch size. This batch size is not important for `GridArchive` but it is important for `Optimizer`, which we'll discuss soon.\n",
    "\n",
    "In `train_model()`, you see we create an `archive = GridArchive((16, 16), [(0, 1000), (-1., 1.)], config=config)`. Let's break this down.\n",
    "\n",
    "- `(16, 16)` specifies that we are creating a 2D 16x16 container for solutions. 16x16 was chosen arbitrarily.\n",
    "\n",
    "- `[(0, 1000), (-1., 1.)]` specifies upper and lower bounds for each dimension of the behavior space. In the case of Lunar Lander, we want to consider timesteps and x-position of the Lunar Lander in the environment. According to OpenAI Gym documention, each simulation can take at least 0 timesteps and at most 1000 timesteps, so we specify `(0, 1000)`. Looking at `LunarLander-v2`'s source code, we find that the minimum x-position value for the lander is -1.0 and the maximum value is 1.0, so we specify `(-1., 1.)`.\n",
    "- `config` is a dictionary that specifies certain configuration settings. As stated previously, the only value that `GridArchive` uses is the seed. `config` will also later be passed into `Optimizer`, which we'll discuss soon.\n",
    "\n",
    "`GridArchive` has a method `as_pandas()` that returns the `GridArchive` as a `pandas` data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianEmitter\n",
    "`GaussianEmitter` is the class that generates solutions to either store in `GridArchive` or discard. As the name implies, it uses a Gaussian distribution to generate/mutate solutions. \n",
    "\n",
    "In `train_model()`, we create `emitter = GaussianEmitter(np.zeros(action_dim * obs_dim), sigma, archive)`. Let's break this down by looking at `GaussianEmitter`'s constructor: `GaussianEmitter(x0, sigma0, archive, config=None)`\n",
    "\n",
    "- `x0` is the center of the Gaussian distribution to generate solutions from when the archive specified by `archive` is empty of solutions. \n",
    "- `sigma0` is the standard deviation of the Gaussian distribution. Here, we simply pass in the sigma value passed into `train_model()`.\n",
    "- `archive` specifies the archive to store solutions in. In this case, we pass in the `GridArchive` we created earlier.\n",
    "- `config` allows you to pass in configuration settings, including specifications for batch sizes. Here, we don't pass anything in because `GaussianEmitter`'s default batch size is 64, which works for us.\n",
    "\n",
    "`GaussianEmitter` has two functions. `ask()` generates a batch of new solutions, either a completely new solution sampled from a Gaussian distribution or a solution generated by mutating (i.e. adding Gaussian noise) an existing solution. `tell()` takes in a batch of solutions, along with their performance values and behavior characteristics, and adds them to the archive specified by `archive` by calling `archive.add()`. `archive.add()` will decide whether or not to store each new solution by comparing each new solution's objective value with their corresponding existing solution's objective value. If for a given new solution there is no corresponding existing solution, then the new solution is automatically stored. `Optimizer`, which we discuss next, takes care of calling `ask()` and `tell()` for you, so you don't need to worry about these details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "`Optimizer` is a class that uses emitters to generate batches of solutions. Then, after the feature/behavior description of each of these solutions have been found, `Optimizer` tells its emitters to store the solutions inside an archive.\n",
    "\n",
    "In `train_model()`, you see that we create `opt = Optimizer(archive, [emitter])`. This is pretty self-explanatory. `archive` is the archive we want our solutions to be stored in. In this case, we created earlier in `train_model()`. We also want to pass in a list of `Emitter`'s we want the `Optimizer` to ask to generate solutions. In our case, we pass in `[emitter]`, which is a list of `Emitter`s just containing the emitter we created earlier in `train_model()`. \n",
    "\n",
    "`Optimizer` has two methods `ask()` and `tell()`. `ask()` asks the `Optimizer`'s list of `Emitter`s to generate a batch of solutions. `tell()` tells the `Optimizer`'s list of `Emitter`s to store a batch of solutions in the archive specified upon the `Optimizer`'s creation. However, in order for the `Emitter`s to know where and if to store each solution in the archive, we have to pass in a couple of additional arguments into `tell()`. \n",
    "\n",
    "Specifically, `tell()` has the following arguments: `def tell(objective_values, behavior_values)`\n",
    "\n",
    "- `objective_values` is an array containing the objective function evaluations for each solution generated by the `Emitter`s we passed into this `Optimizer`. In `train_model()`, you can see we pass in `objs` for this argument. `objs` is a list of reward values derived by running the `simulate()` function described above on each individual solution.\n",
    "- `behavior_values` is a matrix of feature descriptions for each solution. Each row of `behavior_values` describes features of one solution, and these features are used as coordinates to store each solution into an archive. In `train_model()`, we pass in `bcs` as our `behavior_values` argument. The significance of `bcs` was discussed in an earlier section. Check above if you've forgotten.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  `train_model()`\n",
    "\n",
    "We've just gone over the core components of ribs that we'll be using to solve `LunarLander-v2`: `GridArchive`, `Gaussian_Emitter`, and `Optimizer`. Now, take a look at `train_model()` for how exactly we solve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    client: Client,\n",
    "    seed: int,\n",
    "    sigma: float,\n",
    "    model_filename: str,\n",
    "    plot_filename: str,\n",
    "    iterations: int,\n",
    "    env_name: str = \"LunarLander-v2\",\n",
    "):\n",
    "    \"\"\"Trains a model with MAP-Elites and saves it.\"\"\"\n",
    "    # OpenAI Gym environment properties.\n",
    "    env = gym.make(env_name)\n",
    "    action_dim = env.action_space.n\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    \n",
    "    archive = GridArchive((16, 16), [(0, 1000), (-1., 1.)],\n",
    "                          config={\n",
    "                              \"seed\": seed,\n",
    "                          })\n",
    "    emitter = GaussianEmitter(np.zeros(action_dim * obs_dim),\n",
    "                              sigma,\n",
    "                              archive,\n",
    "                              config={\"batch_size\": 64})\n",
    "    opt = Optimizer(archive, [emitter])\n",
    "\n",
    "    for _ in range(0, iterations - 1):\n",
    "        \n",
    "        # Generating a batch of solutions\n",
    "        opt.ask()\n",
    "\n",
    "        objs = list()\n",
    "        bcs = list()\n",
    "        \n",
    "        # Here, we're running each of the solutions (i.e. policies) we generated above through the\n",
    "        # simulate() function. simulate() will return the objective value, timesteps to run to completion,\n",
    "        # and x-position of the lunar lander for each solution we pass in. \n",
    "        futures = client.map(\n",
    "            lambda sol: simulate(env_name, np.reshape(sol, (action_dim, obs_dim)), seed), opt._solutions)\n",
    "\n",
    "        results = client.gather(futures)\n",
    "    \n",
    "        # Here we're just constructing a list of objective function evaluations (i.e. objs) and behavior\n",
    "        # descriptions (i.e. bcs) for each solution. These values were returned by our calls to simulation()\n",
    "        # above.\n",
    "        for reward, x_pos, timesteps in results:\n",
    "            objs.append(reward)\n",
    "            bcs.append((timesteps, x_pos))\n",
    "        \n",
    "        # We have our Optimizer opt tell our Emitters the objective function evaluations and behavior\n",
    "        # descriptions of each solution, so that our Emitter emitter and GridArchive archive can decide \n",
    "        # where and if to store each solution in our GridArchive archive.\n",
    "        opt.tell(objs, bcs)\n",
    "\n",
    "    df = archive.as_pandas()\n",
    "    \n",
    "    # Saving our archive to a file.\n",
    "    df.to_pickle(model_filename)\n",
    "\n",
    "    df = archive.as_pandas()\n",
    "    df = df.pivot('index-0', 'index-1', 'objective')\n",
    "    \n",
    "    # Creating a heatmap of all of our generated solutions.\n",
    "    sns.heatmap(df)\n",
    "    plt.savefig(plot_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `run_evaluation()`\n",
    "This function loads a saved model and runs one simulation of Lunar Lander on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(model_filename, env_name, seed):\n",
    "    \"\"\"Runs a single simulation and displays the results.\"\"\"\n",
    "    model = np.load(model_filename)\n",
    "    print(\"=== Model ===\")\n",
    "    print(model)\n",
    "    cost = simulate(env_name, model, seed, True, 10)\n",
    "    print(\"Reward:\", -cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `map_elites()`, we set up `dask` to parallelize computation and call `train_model()`, which saves an archive of solutions as a pickel file and outputs a heatmap of all solutions in the archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_elites(\n",
    "    seed: int = 42,\n",
    "    local_workers: int = 8,\n",
    "    sigma: float = 10.0,\n",
    "    plot_filename: str = \"lunar_lander_plot.png\",\n",
    "    model_filename: str = \"lunar_lander_model.pkl\",\n",
    "    run_eval: bool = False,\n",
    "):\n",
    "    \"\"\"Uses Map-Elites to train an agent in an environment with discrete actions.\n",
    "    Args:\n",
    "        env: OpenAI Gym environment name. The environment should have a discrete\n",
    "            action space.\n",
    "        seed: Random seed for environments.\n",
    "        sigma: Initial standard deviation for CMA-ES.\n",
    "        local_workers: Number of workers to use when running locally.\n",
    "        plot_filename: Location to store plot image.\n",
    "        model_filename: Location for .npy model file (either for storing or\n",
    "            reading).\n",
    "        run_eval: Pass this to run an evaluation in the environment in `env`\n",
    "            with the model in `model_filename`.\n",
    "    \"\"\"\n",
    "    # Evaluations do not need Dask.\n",
    "    if run_eval:\n",
    "        run_evaluation(model_filename, \"LunarLander-v2\", seed)\n",
    "        return\n",
    "\n",
    "    # Initialize on a local machine. See the docs here:\n",
    "    # https://docs.dask.org/en/latest/setup/single-distributed.html for more\n",
    "    # info on LocalCluster. Keep in mind that for LocalCluster, the\n",
    "    # n_workers is the number of processes. Our LunarLander evaluations do\n",
    "    # not release the GIL (I think), so using threads instead of processes\n",
    "    # (which we would do by setting n_workers=1 and\n",
    "    # threads_per_worker=workers) would be very slow, as it would be\n",
    "    # single-threaded. See here for a bit more info about processes in\n",
    "    # threads in Dask:\n",
    "    # https://distributed.dask.org/en/latest/worker.html#thread-pool\n",
    "    # The link above is for multiple machines (each machine is called a\n",
    "    # worker, and each workers has processes and threads), but the idea\n",
    "    # still holds.\n",
    "    cluster = LocalCluster(n_workers=local_workers,\n",
    "                           threads_per_worker=1,\n",
    "                           processes=True)\n",
    "    client = Client(cluster)  # pylint: disable=unused-variable\n",
    "    print(\"Cluster config:\")\n",
    "    print(client.ncores())\n",
    "\n",
    "    train_model(client, seed, sigma, model_filename, plot_filename, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: box2d-py in /Users/yaya/anaconda/lib/python3.7/site-packages (2.3.8)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/yaya/anaconda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install box2d-py\n",
    "\n",
    "# !pip install box2d-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\r\n",
      "#\r\n",
      "base                     /Users/yaya/anaconda\r\n",
      "caispp                   /Users/yaya/anaconda/envs/caispp\r\n",
      "py35                     /Users/yaya/anaconda/envs/py35\r\n",
      "pyribs_lunar_lander   *  /Users/yaya/anaconda/envs/pyribs_lunar_lander\r\n",
      "ribs                     /Users/yaya/anaconda/envs/ribs\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alabaster==0.7.12\n",
      "appdirs==1.4.4\n",
      "astroid==2.4.2\n",
      "atomicwrites==1.4.0\n",
      "attrs==20.2.0\n",
      "Babel==2.8.0\n",
      "beautifulsoup4==4.9.3\n",
      "bleach==3.2.1\n",
      "box2d-py==2.3.8\n",
      "bump2version==0.5.11\n",
      "certifi==2020.6.20\n",
      "chardet==3.0.4\n",
      "click==7.1.2\n",
      "cloudpickle==1.6.0\n",
      "cma==3.0.3\n",
      "contextvars==2.4\n",
      "coverage==5.3\n",
      "cycler==0.10.0\n",
      "dask==2.30.0\n",
      "dask-jobqueue==0.7.1\n",
      "distlib==0.3.1\n",
      "distributed==2.30.0\n",
      "docutils==0.16\n",
      "filelock==3.0.12\n",
      "fire==0.3.1\n",
      "future==0.18.2\n",
      "gym==0.17.3\n",
      "HeapDict==1.0.1\n",
      "idna==2.10\n",
      "imagesize==1.2.0\n",
      "immutables==0.14\n",
      "importlib-metadata==0.23\n",
      "importlib-resources==3.0.0\n",
      "isort==5.6.4\n",
      "Jinja2==2.11.2\n",
      "kiwisolver==1.3.1\n",
      "lazy-object-proxy==1.4.3\n",
      "livereload==2.6.3\n",
      "MarkupSafe==1.1.1\n",
      "matplotlib==3.3.2\n",
      "mccabe==0.6.1\n",
      "more-itertools==8.6.0\n",
      "msgpack==1.0.0\n",
      "numpy==1.19.4\n",
      "packaging==20.4\n",
      "pandas==1.1.4\n",
      "Pillow==8.0.1\n",
      "pkginfo==1.6.1\n",
      "pluggy==0.13.1\n",
      "psutil==5.7.3\n",
      "py==1.9.0\n",
      "py-cpuinfo==7.0.0\n",
      "pydata-sphinx-theme==0.4.1\n",
      "pyglet==1.5.0\n",
      "Pygments==2.7.2\n",
      "pylint==2.6.0\n",
      "pyparsing==2.4.7\n",
      "pytest==4.6.5\n",
      "pytest-benchmark==3.2.3\n",
      "pytest-cov==2.10.1\n",
      "python-dateutil==2.8.1\n",
      "pytz==2020.4\n",
      "PyYAML==5.3.1\n",
      "readme-renderer==28.0\n",
      "requests==2.24.0\n",
      "requests-toolbelt==0.9.1\n",
      "-e git+git@github.com:icaros-usc/pyribs.git@f9f1593e0a04cab3988f1185e76642e4d9eff5a3#egg=ribs\n",
      "scipy==1.5.3\n",
      "seaborn==0.11.0\n",
      "six==1.15.0\n",
      "snowballstemmer==2.0.0\n",
      "sortedcontainers==2.2.2\n",
      "soupsieve==2.0.1\n",
      "Sphinx==3.2.1\n",
      "sphinx-autobuild==2020.9.1\n",
      "sphinx-book-theme==0.0.37\n",
      "sphinxcontrib-applehelp==1.0.2\n",
      "sphinxcontrib-devhelp==1.0.2\n",
      "sphinxcontrib-htmlhelp==1.0.3\n",
      "sphinxcontrib-jsmath==1.0.1\n",
      "sphinxcontrib-qthelp==1.0.3\n",
      "sphinxcontrib-serializinghtml==1.1.4\n",
      "tblib==1.7.0\n",
      "termcolor==1.1.0\n",
      "toml==0.10.2\n",
      "toolz==0.11.1\n",
      "tornado==6.1\n",
      "tox==3.14.0\n",
      "tqdm==4.51.0\n",
      "twine==1.14.0\n",
      "typed-ast==1.4.1\n",
      "urllib3==1.25.11\n",
      "virtualenv==20.1.0\n",
      "wcwidth==0.2.5\n",
      "webencodings==0.5.1\n",
      "wrapt==1.12.1\n",
      "yapf==0.30.0\n",
      "zict==2.0.0\n",
      "zipp==3.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaya/anaconda/lib/python3.7/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 56946 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster config:\n",
      "{'tcp://127.0.0.1:56957': 1, 'tcp://127.0.0.1:56958': 1, 'tcp://127.0.0.1:56959': 1, 'tcp://127.0.0.1:56960': 1, 'tcp://127.0.0.1:56961': 1, 'tcp://127.0.0.1:56962': 1, 'tcp://127.0.0.1:56963': 1, 'tcp://127.0.0.1:56964': 1}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'gym.envs.box2d' has no attribute 'LunarLander'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-42a5cdea42a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmap_elites\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-08efef943da5>\u001b[0m in \u001b[0;36mmap_elites\u001b[0;34m(seed, local_workers, sigma, plot_filename, model_filename, run_eval)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-845b7e1800ec>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(client, seed, sigma, model_filename, plot_filename, iterations, env_name)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m\"\"\"Trains a model with MAP-Elites and saves it.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# OpenAI Gym environment properties.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0maction_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mobs_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Making new env: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;31m# We used to have people override _reset/_step rather than\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# reset/step. Set _gym_disable_underscore_compat = True on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'gym.envs.box2d' has no attribute 'LunarLander'"
     ]
    }
   ],
   "source": [
    "map_elites()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
