{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illuminating the Latent Space of an MNIST GAN\n",
    "\n",
    "One of the most popular applications of [Generative Adversarial Networks](https://en.wikipedia.org/wiki/Generative_adversarial_network) is generating fake images. In particular, websites like [this person does not exist](https://thispersondoesnotexist.com) serve a GAN that generates fake images of people ([this x does not exist](https://thisxdoesnotexist.com) provides a comprehensive list of such websites). Such websites are entertaining, especially when one is asked to figure out [which face is real](https://www.whichfaceisreal.com/index.php).\n",
    "\n",
    "Usually, these websites extract fake images by sampling the GAN’s latent space. For those unfamiliar with GANs, this means that each image is associated with a real valued vector of $n$ components. But since these vectors are typically generated randomly, the usefulness of these websites breaks down when we wish to search for a specific image.\n",
    "\n",
    "For instance, suppose that instead of fake faces, we want to generate fake handwriting, specifically the digit eight (8). We could train a GAN on the MNIST dataset and produce a generator network that generates fake digits. Now, we can repeatedly sample the latent space until an eight appears. However, if we want to _find_ an eight, we could optimize latent space directly with CMA-ES. To ensure that we generate eights, we could use the output classification prediction of a LeNet-5 classifier as the objective (see [Bontrager 2018](https://arxiv.org/abs/1705.07386)).<sup>1</sup> But notice that the latent space likely contains many examples of the digit eight, and they might vary in the weight of the pen stroke or the lightness of the ink color. If we make these properties our measures, we could search latent space for many different examples of eight in a single run!\n",
    "\n",
    "[Fontaine 2021](https://arxiv.org/abs/2007.05674) takes exactly this approach when generating new levels for the classic video game [Super Mario Bros](https://en.wikipedia.org/wiki/Super_Mario_Bros). They term this approach “Latent Space Illumination”, as they explore quality diversity (QD) algorithms (including [CMA-ME](https://arxiv.org/pdf/1912.02400.pdf)) as a method to search the latent space of a video game level GAN and illuminate the behavior space of possible level mechanics. In this tutorial, we illuminate the latent space of the aforementioned MNIST GAN by mimicking the approach taken in [Fontaine 2021](https://arxiv.org/abs/2007.05674).\n",
    "\n",
    "**(1)** Since the discriminator of the GAN is only trained to evaluate how realistic an image is, it cannot detect specific digits. Hence, we need the LeNet-5 to check that the digit is an 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, we install pyribs, PyTorch, and several utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ribs torch==1.7 torchvision==0.8 numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we check what device is available for PyTorch. On Colab, activate the GPU by clicking \"Runtime\" in the toolbar at the top. Then, click \"Change Runtime Type\", and select \"GPU\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the GAN and Classifier\n",
    "\n",
    "For this tutorial, we pretrained a GAN that generates MNIST digits using the code from [a beginner GAN tutorial](https://debuggercafe.com/generating-mnist-digit-images-using-vanilla-gan-with-pytorch/). We also pretrained a [LeNet-5](https://en.wikipedia.org/wiki/LeNet) classifier for the MNIST dataset using the code [here](https://github.com/icaros-usc/pyribs/tree/master/examples/tools/train_mnist_classifier.py). Below, we define the network structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Generator network for the GAN.\"\"\"\n",
    "\n",
    "    def __init__(self, nz):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Size of the latent space (number of dimensions).\n",
    "        self.nz = nz\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.nz, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(-1, 1, 28, 28)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator network for the GAN.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.n_input = 784\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.n_input, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        return self.main(x)\n",
    "\n",
    "\n",
    "LENET5 = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, (5, 5), stride=1, padding=0),  # (1,28,28) -> (6,24,24)\n",
    "    nn.MaxPool2d(2),  # (6,24,24) -> (6,12,12)\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(6, 16, (5, 5), stride=1, padding=0),  # (6,12,12) -> (16,8,8)\n",
    "    nn.MaxPool2d(2),  # (16,8,8) -> (16,4,4)\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),  # (16,4,4) -> (256,)\n",
    "    nn.Linear(256, 120),  # (256,) -> (120,)\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(120, 84),  # (120,) -> (84,)\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(84, 10),  # (84,) -> (10,)\n",
    "    nn.LogSoftmax(dim=1),  # (10,) log probabilities\n",
    ").to(device)\n",
    "LENET5_MEAN_TRANSFORM = 0.1307\n",
    "LENET5_STD_DEV_TRANSFORM = 0.3081"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the pretrained weights for each network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "from pathlib import Path\n",
    "\n",
    "LOCAL_DIR = Path(\"lsi_mnist_weights\")\n",
    "LOCAL_DIR.mkdir(exist_ok=True)\n",
    "WEB_DIR = \"https://raw.githubusercontent.com/icaros-usc/pyribs/master/examples/tutorials/_static/\"\n",
    "\n",
    "# Download the model files to LOCAL_DIR.\n",
    "for filename in [\n",
    "        \"mnist_generator.pth\",\n",
    "        \"mnist_discriminator.pth\",\n",
    "        \"mnist_classifier.pth\",\n",
    "]:\n",
    "    model_path = LOCAL_DIR / filename\n",
    "    if not model_path.is_file():\n",
    "        urlretrieve(WEB_DIR + filename, str(model_path))\n",
    "\n",
    "# Load the weights of each network from its file.\n",
    "g_state_dict = torch.load(\n",
    "    str(LOCAL_DIR / \"mnist_generator.pth\"),\n",
    "    map_location=device,\n",
    ")\n",
    "d_state_dict = torch.load(\n",
    "    str(LOCAL_DIR / \"mnist_discriminator.pth\"),\n",
    "    map_location=device,\n",
    ")\n",
    "c_state_dict = torch.load(\n",
    "    str(LOCAL_DIR / \"mnist_classifier.pth\"),\n",
    "    map_location=device,\n",
    ")\n",
    "\n",
    "# Instantiate networks and insert the weights.\n",
    "generator = Generator(nz=128).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "generator.load_state_dict(g_state_dict)\n",
    "discriminator.load_state_dict(d_state_dict)\n",
    "LENET5.load_state_dict(c_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSI with CMA-ME on MNIST GAN\n",
    "\n",
    "After loading the GAN and the classifier, we can begin exploring the latent space of the GAN with the pyribs implementation of CMA-ME. Thus, we import and initialize the `GridArchive`, `EvolutionStrategyEmitter`, and `Scheduler` from pyribs.\n",
    "\n",
    "For the `GridArchive`, we choose a 2D measure space with \"boldness\" and \"lightness\" as the measures. We approximate \"boldness\" of a digit by counting the number of white pixels in the image, and we approximate \"lightness\" by averaging the values of the white pixels in the image. We define a \"white\" pixel as a pixel with value at least 0.5 (pixels are bounded to the range $[0,1]$). Since there are 784 pixels in an image, boldness is bounded to the range $[0, 784]$. Meanwhile, lightness is bounded to the range $[0.5, 1]$, as that is the range of a white pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ribs.archives import GridArchive\n",
    "\n",
    "archive = GridArchive(\n",
    "    solution_dim=generator.nz,\n",
    "    dims=[200, 200],  # 200 bins in each dimension.\n",
    "    ranges=[(0, 784), (0.5, 1)],  # Boldness range, lightness range.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use 5 instances of `EvolutionStrategyEmitter` with `2imp` ranker, each with batch size of 30. Each emitter begins with a zero vector of the same dimensionality as the latent space and an initial step size $\\sigma=0.2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ribs.emitters import EvolutionStrategyEmitter\n",
    "\n",
    "# We use the EvolutionStrategyEmitter to create a ImprovementEmitter.\n",
    "emitters = [\n",
    "    EvolutionStrategyEmitter(\n",
    "        archive=archive,\n",
    "        x0=np.zeros(generator.nz),\n",
    "        sigma0=0.2,  # Initial step size.\n",
    "        ranker=\"2imp\",\n",
    "        batch_size=30,\n",
    "    ) for _ in range(5)  # Create 5 separate emitters.\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we construct the optimizer to connect the archive and emitters together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ribs.schedulers import Scheduler\n",
    "\n",
    "scheduler = Scheduler(archive, emitters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the components created, we now generate latent vectors. As we use 5 emitters with batch size of 30 and run 30,000 iterations, we evaluate 30,000 * 30 * 5 = 4,500,000 latent vectors in total. This loop should take **15-30 min** to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000 complete after 22.63s - Archive size: 14755\n",
      "Iteration 2000 complete after 43.19s - Archive size: 19571\n",
      "Iteration 3000 complete after 63.63s - Archive size: 20254\n",
      "Iteration 4000 complete after 83.61s - Archive size: 20533\n",
      "Iteration 5000 complete after 106.20s - Archive size: 20769\n",
      "Iteration 6000 complete after 126.45s - Archive size: 20800\n",
      "Iteration 7000 complete after 144.89s - Archive size: 20877\n",
      "Iteration 8000 complete after 163.25s - Archive size: 20900\n",
      "Iteration 9000 complete after 181.85s - Archive size: 20927\n",
      "Iteration 10000 complete after 199.89s - Archive size: 20945\n",
      "Iteration 11000 complete after 217.93s - Archive size: 20981\n",
      "Iteration 12000 complete after 236.13s - Archive size: 21001\n",
      "Iteration 13000 complete after 254.18s - Archive size: 21028\n",
      "Iteration 14000 complete after 272.47s - Archive size: 21077\n",
      "Iteration 15000 complete after 290.93s - Archive size: 21110\n",
      "Iteration 16000 complete after 308.99s - Archive size: 21120\n",
      "Iteration 17000 complete after 326.71s - Archive size: 21136\n",
      "Iteration 18000 complete after 344.68s - Archive size: 21149\n",
      "Iteration 19000 complete after 362.26s - Archive size: 21164\n",
      "Iteration 20000 complete after 379.89s - Archive size: 21173\n",
      "Iteration 21000 complete after 397.67s - Archive size: 21205\n",
      "Iteration 22000 complete after 415.79s - Archive size: 21224\n",
      "Iteration 23000 complete after 433.96s - Archive size: 21228\n",
      "Iteration 24000 complete after 452.20s - Archive size: 21242\n",
      "Iteration 25000 complete after 469.96s - Archive size: 21251\n",
      "Iteration 26000 complete after 487.37s - Archive size: 21260\n",
      "Iteration 27000 complete after 504.79s - Archive size: 21295\n",
      "Iteration 28000 complete after 522.33s - Archive size: 21307\n",
      "Iteration 29000 complete after 539.74s - Archive size: 21319\n",
      "Iteration 30000 complete after 557.19s - Archive size: 21328\n"
     ]
    }
   ],
   "source": [
    "total_itrs = 30_000\n",
    "flat_img_size = 784  # 28 * 28\n",
    "start_time = time.time()\n",
    "\n",
    "for itr in range(1, total_itrs + 1):\n",
    "    sols = scheduler.ask()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tensor_sols = torch.tensor(\n",
    "            sols,\n",
    "            dtype=torch.float32,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        # Shape: len(sols) x 1 x 28 x 28\n",
    "        generated_imgs = generator(tensor_sols)\n",
    "\n",
    "        # Normalize the images from [-1,1] to [0,1].\n",
    "        normalized_imgs = (generated_imgs + 1.0) / 2.0\n",
    "\n",
    "        # We optimize the score of the digit being 8. Other digits may also be\n",
    "        # used.\n",
    "        lenet5_normalized = ((normalized_imgs - LENET5_MEAN_TRANSFORM) /\n",
    "                             LENET5_STD_DEV_TRANSFORM)\n",
    "        objs = torch.exp(LENET5(lenet5_normalized)[:, 8]).cpu().numpy()\n",
    "\n",
    "        # Shape: len(sols) x 784\n",
    "        flattened_imgs = normalized_imgs.cpu().numpy().reshape(\n",
    "            (-1, flat_img_size))\n",
    "\n",
    "        # The first measures is the \"boldness\" of the digit (i.e. number of white\n",
    "        # pixels). We consider pixels with values larger than or equal to 0.5\n",
    "        # to be \"white\".\n",
    "        # Shape: len(sols) x 1\n",
    "        boldness = np.count_nonzero(flattened_imgs >= 0.5,\n",
    "                                    axis=1,\n",
    "                                    keepdims=True)\n",
    "\n",
    "        # The second measures is the \"lightness\" of the digit (i.e. the mean value of\n",
    "        # the white pixels).\n",
    "        # Shape: len(sols) x 1\n",
    "        flattened_imgs[flattened_imgs < 0.5] = 0  # Set non-white pixels to 0.\n",
    "        # Add 1 to avoid dividing by zero.\n",
    "        lightness = (np.sum(flattened_imgs, axis=1, keepdims=True) /\n",
    "                     (boldness + 1))\n",
    "\n",
    "        # Each measures entry is [boldness, lightness].\n",
    "        meas = np.concatenate([boldness, lightness], axis=1)\n",
    "\n",
    "    scheduler.tell(objs, meas)\n",
    "\n",
    "    if itr % 1000 == 0:\n",
    "        print(\n",
    "            f\"Iteration {itr} complete after {time.time() - start_time:.2f}s - \"\n",
    "            f\"Archive size: {len(archive.as_pandas(include_solutions=False))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "\n",
    "\n",
    "def show_grid_img(x_start,\n",
    "                  x_num,\n",
    "                  x_step_size,\n",
    "                  y_start,\n",
    "                  y_num,\n",
    "                  y_step_size,\n",
    "                  archive,\n",
    "                  figsize=(8, 6)):\n",
    "    \"\"\"Displays a grid of images from the archive.\n",
    "    \n",
    "    Args:\n",
    "        x_start (int): Starting index along x-axis.\n",
    "        x_num (int): Number of images to generate along x-axis.\n",
    "        x_step_size (int): Index step size along x-axis.\n",
    "        y_start (int): Starting index along y-axis.\n",
    "        y_num (int): Number of images to generate along y-axis.\n",
    "        y_step_size (int): Index step size along y-axis.\n",
    "        archive (GridArchive): Archive with results from CMA-ME.\n",
    "        figsize ((int, int)): Size of the figure for the image.\n",
    "    \"\"\"\n",
    "    x_range = np.arange(x_start, x_start + x_step_size * x_num, x_step_size)\n",
    "    y_range = np.arange(y_start, y_start + y_step_size * y_num, y_step_size)\n",
    "    grid_indices = [(x, y) for y in np.flip(y_range) for x in x_range]\n",
    "\n",
    "    imgs = []\n",
    "    img_size = (28, 28)\n",
    "    df = archive.as_pandas()\n",
    "    solutions, indices = df.solution_batch(), df.index_batch()\n",
    "    try:\n",
    "        sol = solutions[np.where(indices == archive.grid_to_int_index(grid_indices))][0]\n",
    "    except IndexError:\n",
    "        print(f\"There is no solution at index {index}.\")\n",
    "        return\n",
    "    \n",
    "    for index in grid_indices:\n",
    "        with torch.no_grad():\n",
    "            img = generator(\n",
    "                torch.tensor(sol.reshape(1, generator.nz),\n",
    "                             dtype=torch.float32,\n",
    "                             device=device))\n",
    "            # Normalize images to [0,1].\n",
    "            normalized = (img.reshape(1, *img_size) + 1) / 2\n",
    "            imgs.append(normalized)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    img_grid = make_grid(imgs, nrow=x_num, padding=0)\n",
    "    plt.imshow(np.transpose(img_grid.cpu().numpy(), (1, 2, 0)),\n",
    "               interpolation='nearest',\n",
    "               cmap='gray')\n",
    "\n",
    "    # Change labels to be BC values.\n",
    "    plt.xlabel(\"Boldness\")\n",
    "    plt.ylabel(\"Lightness\")\n",
    "    x_ticklabels = [\n",
    "        round(archive.boundaries[0][i])\n",
    "        for i in [x_start + x_step_size * k for k in range(x_num + 1)]\n",
    "    ]\n",
    "    y_ticklabels = [\n",
    "        round(archive.boundaries[1][i], 2) for i in [\n",
    "            y_start + y_step_size * y_num - y_step_size * k\n",
    "            for k in range(y_num + 1)\n",
    "        ]\n",
    "    ]\n",
    "    plt.xticks([img_size[0] * x for x in range(x_num + 1)], x_ticklabels)\n",
    "    plt.yticks([img_size[0] * x for x in range(y_num + 1)], y_ticklabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Below, we visualize the archive after all evaluations. The x-axis is the boldness and the y-axis is the lightness. The color indicates the objective value. We can see that we found many images that the classifier strongly believed to be an eight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdUAAAGDCAYAAAB9boodAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABJY0lEQVR4nO3de5ycZX3//9dnZo/ZbI6bQCABAkQQT6hRoVqlCIJa4UepFlsVrcpX66lfW1vp11q17a9qW1vrj9rSilStWq1VsUrxrF9tpUBFRBCIgCSBEHLaJMtmT/P5/XFd18ydyezubHZO9+77mcc8Zua+77n3ms3ufua67s/1uczdERERkfkrtLsBIiIiC4WCqoiISIMoqIqIiDSIgqqIiEiDKKiKiIg0iIKqiIhIgyioioiINIiCqghgZveb2XnT7PsDM7vPzA6a2TYz+5fMvm+b2Wumed0rzczN7K+qtl8ct18bn58Un3+l6rhPmNm74uNzzGxbZt/jzOyrZrbHzPaZ2S1m9gIz+43YzoNmNmpmpczzg0f7/RGR+iioiszAzC4HXg6c5+5Lgc3AN+Zwip8BLzGzrsy2y4G7axz7DDP7hTrP+yXga8CxwFrgzcB+d/9nd18a2/p84MH0PG4TkSZSUBWZ2dOAG9z9ZwDuvsPdr57D63cAPwYuADCzVcAvANfVOPb9wJ/OdkIzGwI2Av/g7uPx9n13/94c2iUiTaCgKjKzHwCvMLO3mdlmMysexTk+BrwiPr4M+CIwVuO4vwUeM90wdMZuYAvwCTP7f8zsmKNok4g0gYKqyAzc/RPAmwg9ze8AO83s9+d4ms8D55jZckJw/dg0x40Seqp/MkubHPgl4H7gL4GHzOy7ZrZpju0SkQZTUBWZRbxOeR6wAngd8MdmdsEcXj8KfBl4B7Da3b8/w+H/CBxjZi+a5Zzb3P2N7n4KcCIwwvTBWkRaREFVpE7uPuHunwVuAx4/x5d/DPgd4BOzfI1x4N3AHwNWZ7u2AlcdRZtEpMEUVEUqus2sL3PritNiXmhmg2ZWMLPnA48Dbpzjub8DnA98qI5jPw70ARfW2mlmK83s3WZ2amzTEPCbhOu/ItJGCqoiFV8hXNdMt3cB+4E/AB4A9hEydF8/10xbD77h7nvqOHYKeCewappDxoGTgK/H9t1OSHx65VzaJCKNZ1qkXEREpDHUUxUREWmQpgVVM7vGzHaa2e3T7Dcz+xsz22Jmt5nZU5rVFhERkWrNiFPN7KleyzSJFtHzgU3xdgXw4Sa2RUREpNq1NDhONS2ouvt3gZmSMi4GPhYTOH4ArDCzdc1qj4iISFYz4lQ7r6keD2zNPN8Wt4mIiHSCOceprpl2dgozu4LQ9WZgYOCpp59+eptbJCIiALfccssud1/TjHNfcMHTfffu4aN+/S233P0T4FBm09VzXBBjztoZVLcDGzLP18dtR4jfhKsBNm/e7DfffHPzWyciIrMys58369y7dw1z441Hn27T1f3cQ+6+eR5NqDtOJe0c/r2OsPqHmdlZwLC7P9TG9oiISEdxKJWO/jZ/c45TTeupmtmngHOAITPbBvwR0A3g7n9HqF7zAsISVo8Cr2pWW6T5pkrfBqBYOOeIbTPJHt9K1W1rVztEZBaNCY41NSNONS2ouvtLZ9nvwBua9fVFRERm0ow4lYtEJQmmSt8u96hq9Qyzx023rxltqmfbbK+vfl9ZM73H6Y6t9b2qpx0zfc1axzbqe9zK/zOR3HAgZ6V0FVTbpFHBJHuemfal59XnPNph2+kc7Wtnet3RBOn5tKX6tfUG2EZo97B0vT+Hc3n9XM8hUuFNHf5tBgVVERHpXAqqUq2e3uRsr6v3a8y2b7rjGt3jWkja+b2Z6WvXGl1oRK/yaI+r9xz1XMIQySsF1Qaa7Y9PM4ZGZfGa7/Xsdqnng2U9lz4UjBcBRz1VERGRxtA11UVHQ1gijTeXjO16f/fm87ta75xr/T1oMPVURUREGsUxV1BdMOaSXJGHa1kiC9Fcf/ea9bta13SuUoli17lN+frSGRRUa8hrAoiIdLhCO8ut55SGf0VERBrAgZIqKi0K6rmKiDSbsn9FREQaI4fZv4t+gH+q9G31OkVEpCEWXU91avKbAEdk4Cmwioh0IE2pERERaQRdU+1YU3u/GB4MDobn6pmKSIup0tIc5TD7d1FcU9246pehqyvcRETaJOVwHFYoYvzrTI1/vX2NkoZSlBERkQ6l4d+OtNrXt7sJIiKHKfdWq6osTY3eQLH/gtY3qFMpqIqIiDSAgymodp4bt+hTn4h0tux11amR6wEoDjy/Xc3pEA6er0SlRRFUGRyEsbHwWAWtRaSTVP9N6uqCycn2tEXmbXEEVRERyScN/3aO0q7PhQcDS6G/v72NERGZSbbHGqf/pQpw5cAyMbG4hoRzWPt3QQdVERHJM89d8YcFGVR3XPoaANa+/5lhQ/+SNrZGRGSeYi92UfVSQT3VTnHvzpUArFm1KmwoFtvYGhGRxpga/zrFnvPC49EbADSntcMsyKAqIiILhHqq7dPbsw6AA79zftigWr8ishDEwJJ6qbBYeqiapyoiItIYObymuqAqIbiXcC/xuRtO4nM3nFTZoYIPIpJnhYL+juXEguqpOuETzUVn3Rc2FM5uY2tERI5Sde8sVVhaUH+x66QpNSIiIo2gpd/a6opj3wRAsf+ew3do2ERE8iglKPU9r80NaZMcXlNdUEF142C471od31YaMunuVmAVkc6WCR7FrnOBw1euWbRyNvyrSCMiItIgC6qnOhE/6Fl/fFvqnYpI3pRK5UL62Xmpi5ODa/hXRERk/pzcDf8uqKD6W2f9DIDC8WsAyNfnGxFZFNK106qRtPJ11LTcmwRKVGqfW+4OZQqfddyDABRfqOFfEekw1ZelykE2Ph8dpTj4wpY2SRpnQQVVERFZQDT8215POvFhALqfGId/0yfAUklJSyLSWaYZ1lQvNUvFH0RERBpHPdX2+fmOsDj5yuHRsGGahAARkY4xGv9eDba3GR3J0ZSadnjeyrcD8P4zwyca6y4C4f8D0PCviHSOqg/7abi3PDc1ZgFLPi2IoCoiIguRa/i3Hb66970AjPzWy8OGY04M96l3ql6qiHSK9PdofByAqanrASgOPL9dLepsCqqtd+nQHwLwqdda2NDfG+6V/SsiHWrRrjwzF1qlRkREpIFy1lNdEN237kKB7kKBfVu62belG8bGYWwcmwg3EZFOMzX+dS3ttgCppyoiIp3JlajUFu7hm75lxyoA1qxbG3ZMTrWrSSIitcVrhIV77w3PT29jW/JA11Rbb8/EGACbjtsdNuwcCPfHHtOmFomI1FAqweQkAN7fB4C1sz154PnqqS6Ia6oiIiKdYEH0VL+2730A7HvF5WHDrv3h/sCBcL9qVRtaJSISpSHMkRHo7w+PdXlqdjlcpaapPVUzu9DM7jKzLWb29hr7TzSzb5jZbWb2bTNb38z2iIhInsREpaO9zaKOGHWCmX3LzH4Y49QLZjtn03qqZlYErgLOB7YBN5nZde5+R+awvwA+5u7/ZGbnAn8GvHyuX+v3T34PAO+5NH4aPG51uE8FH1T8QUQ6weQktnMnADY21ubG5ESTEpXqjFHvAD7j7h82szOArwAnzXTeZkaapwNb3P1edx8HPg1cXHXMGcA34+Nv1dhfl6IZRTO61vbQtbYHduwJt/7+ylCLiEi7jI6G2+AgTEzAxATe34/r79PM0vBvc3qq9cQoB5bFx8uBB2c7aTOD6vHA1szzbXFb1o+AX4mPLwEGzWx1E9skIiIC9cWodwEvM7NthF7qm2Y7absTlX4X+P/M7JXAd4HtwBFX783sCuAKgBNOOOGIk3hc5O3Ru0P1pKVPXh5eFxOVXIlKItIOcejSxg6F56OPUth4eRsblEPzS1QaMrObM8+vdver5/D6lwLXuvtfmtnZwMfN7PHu0y/y2syguh3YkHm+Pm4rc/cHiT1VM1sKXOru+6pPFL8JVwNs3rw5X6lgIiJydOZfUWmXu2+eZt+sMQp4NXBhaIr/l5n1AUPAzum+YDOHf28CNpnZRjPrAS4DrsseYGZDZpbacCVwzVy/yAmrLuTRSXh0EoZ39jO8sx+GR8ItXrtQkpKItMXYGIyN4VbArQCFAqWtn6C09RPtbllueMmP+jaLWWMU8ADwXAAzeyzQBzwy00mbFm3cfRJ4I3ADcCchg+onZvYeM7soHnYOcJeZ3Q0cA/zpXL/OA3v+gyVdsKQLlq8dZfnaUVi9LNxGRsMtZ2WuRCTnSqVw6+0Nt4GBcJucorDhZRQ2vKzdLcwP96O/zXjaumLU7wCvNbMfAZ8CXuk+84mbek3V3b9CuLib3fbOzON/Bf61mW0QERGppY4YdQfwzLmcs92JSvN2zIpn8U+nPxuAQjFu7A5vy0/cMM2rRESaII2KpUtOw8PhfnAQAO/tbUOjckwVlVrv4X3f4+BkkYOTRYYf7mP44T7YtQ927cN27cJ27QrDAIWCrq2KSHOlvzPxWip9feE2MgIjIxRXHtVU/MWtiRWVmiH3PVUREVmgcrieau67bmuWP4PugtNdcFYcf4gVxx+Cnq5wExFppcnJcEuJSuPjMD5OcfmLKC5/UbtbJy2gyCMiIp0rZz3VBRFUB7vCor+WEpXif4KnRco1pUZEmi31TtNjKC9ILkevjvmmHSX3QbW/uJLeYvgB3r+9B4C+8fiDvHdfuF+2/MisPBGRRsqshlX46V1h08kb29mi/Mth9m/ug6qIiCxgCqqtVaSLAxPhbaw6I/ZQJ2NN/q749kZHQzUTEZFGGw8LedDVFf7WAL7u2LBNI2OLTu6DqoiILFA5nFKT+6C62tfTUwjXS8d3hvuuNSsAsLExIFYx0SdGEWmE6vyMNCI2MVE+pLD+11vcqAVslhq+nSb3QfURe4B7Dq4D4Kz0bg48Gu7jCEz4tKNEJRFpoOoM38nJylCwNIQD069c2plyH1RFRGSBUvZv6/XaUjYtDckBxZSL1BV6o75sWXheLNZ4pYjIUUijXalXOjVV3mV561ZJw+U+qE74o5yyeh8A++/vBmCovy/sjNdUKZUq1z1EROYjDfem4JqCaqlEYejS9rRpIVNPVUREpDHy1vlfEEH1zkdWAfDc520PGx7ZB4CtWwuAT0xUeqpKVBKRo5WK5cNhw74ANjoKy9vQpoUsh9dUFWFEREQaJPc91RIlHni0F4DxXXGe6uplRx6oHqqIHK1sYfw0b7J6oY6Rkda1ZzHR8G9rOSXOWfcIAL3r49tJBfXTZOzubs1TFZGjly4fjY9X/pakbTHgFk55VRsatsC5a5UaERGRhlFPtbW66OXufSE74ITdwwAUB5eEnekTTjZRSUSkXrXWRU2jXXFbcfCFLW7UIpOvjqoSlURERBol9903o8Ce8fA2ioPxM8LOveF+cGnlQF1LFZG5qs7FmJoq91BtNNYYH2xDuxYLR9dUW63EBEu7wg++j8dv/kCsqFSwcN/bq0QlEalf+nuR7nt6wv3ISPlvSGHti9vQsEVI11RFREQaQxWVWswosmc8FMwvjaXEpJhUMB6n1JRK6qGKSP2q/16kOuKpxyqt4ain2irFYrheun75szljWZh0Pb4nDPf2dqdFg2tk7ImITCdl+VYXdsgMByvbV2aS26AqIiILmxYpb4M1fgLf3BnS75561o6wceQQAKWznxaej42poL6I1C/9nUjDvvG5eqktpuFfERGRxvF8zajJb1DtKoYqSo/YA5w8cAwAhcGQsER/KLBf2B6WgiuddFLL2yciHa56ml22alLa190d7vP2l13aJrdBteTjABTp5sBk+KWY3B3WN+waC/vYHYtAnHyyhn1F5HDVfxO6uo6cn5qC6aFwSYn+1jRNKnRNVUREpBF0TbV1SqWQQNBlvfQXw3fd0gfPrjgMvHpluC8UVFFJRILqvwXZ6TPVPdT4vLjy4hY1TqqppyoiItIgebucndug2tMdeqErS2uZKIWiD8Xl8ZPngdFwn53IrR6qiGRlE5MgFMsvxlGueF/sv6DFjZK8y21QLZXCL8RWbqdg54SN5QL6MWMvzU2dmlJQFZFguuFfM4o957WnTVKbA7HTlBe5DaoiIrKwqaJSCxULobD10sJaVvWEXuv4jjil5knhk433hvmqGv4VWeSyyUjT/C2wgwegr0XtkToZ7uqpioiIzJ+rp9oyvV2h3u+kj7GkGHqohZhjwGRctHzZsvC8WNSUGpHFLDutropt3RoOOeVVrWyRLFC5DaqjE6Fa0pO6zuf2/aHMyS+mdzMVg+zDDwNQesxjWt4+EWmD6sBZay5qVOw6Nzw4pcltknlRT1VERKQBHHRNtVW6i0sAKFJkPHRMKfTHb/5AyDYobdgQnk9MVApji8jCVd0zrVUtKd5PTdwAaC5qR3NwTalpjYmpRwHYW9jHhC89bF/p2WeHB2mearGoa6kii1l2BsBoKA5TXP6iNjZIFqrcBlUREVn4VKawRTxeve72HjYtDfNUx0JeEku/+T0ASs96etgwMNDy9olIB8mOVPX0tK8dMme6pioiItIguqbaIoVCaHq/9zIWv+l9J8ZPoyNhWTjbtw8AX7685e0TkRbLJiWlYvmph1oohIRFlJiUJ+4a/m2ZicmDAIzZOPeNhLcxsTOWKXxsqALhQ0PtaZyINN50hfCzgTOJSYppLurU8JeUmCQtkdugKiIiC51q/7ZMV5ynOsgAj06G8YGe9XEual9IRCg89BAApZNP1pQakbyb7Xd4fLwyja6qgpJ6qflV0jVVERGRBtA11dZJU2qWFrp50opwLXX3zeETzZqh4XDML6wJB6uXKrJwVF9LHR+vPI/JSFi+ejdSm8oUtpB7yO7bWtrNfSPHArB8Q/jlsjVrwzF9WhxRZEGotcJM3Fa4997w9NRTldkrbZfboCoiIgtf3nqqTR0XNbMLzewuM9tiZm+vsf8EM/uWmf3QzG4zsxfUe+5CoYdCoYfhwi6O6StxTF+Jgw91cfChLlh/TLiJSL6VSpVbZPv2Yvv2Uuw6N0yZKRSgUKBw+0/a2FBplpLbUd9mM1uMise8xMzuMLOfmNknZztn03qqZlYErgLOB7YBN5nZde5+R+awdwCfcfcPm9kZwFeAk+o5fxr+HZpax76J8Nmguy/+4g2EzODyBPDe3nm9FxFpkWkWEs9eL/UVKwGYOvRVAIqnXxFees9HyFefRmbl1rSKSvXEKDPbBFwJPNPd95rZ2tnO28ye6tOBLe5+r7uPA58GLq46xoFl8fFy4MEmtkdERCSpJ0a9FrjK3fcCuPvO2U7azGuqxwNbM8+3Ac+oOuZdwFfN7E3AAHBerROZ2RXAFQAnnHBC3Bo+DzxceID+4ioABs+OhfPvui/cn3hiuJ+cVBFtkU6WeqhxWTYbDhn89MVRpr37ynNQfVn4HF749g/CvkufF55venVLmiqtE7J/53WKITO7OfP8ane/Oj6uJ0Y9BsDMvg8UgXe5+3/M9AXbnaj0UuBad/9LMzsb+LiZPd7TfJkofhOuBti8eXPOZi2JiMjRqufa6Ax2ufvmeby+C9gEnAOsB75rZk9w930zvaBZtgMbMs/Xx21ZrwYuBHD3/zKzPmAImLWLDSHunlTaxHgcc5/cGuoBd58SptiU56qplyrSuSYnyz1VGzsUtvXE6miHwuIYPjRUOWb//nB/6fta205piyZm/9YTo7YBN7r7BHCfmd1NCLI3TXfSZl5TvQnYZGYbzawHuAy4ruqYB4DnApjZY4E+4JF6Tm7WhVkXx/T0s6ToLCk6e+7sYc+dPfDg7nBLSxxMl/wgIu2TsnqnpsIH354e3Aq4FcIw8OhoGPLt6qJwy49gcBAGBylsvJzCxsvb3XppAaep2b/1xKgvEHqpmNkQYTj43plO2rSg6iE9943ADcCdhCzfn5jZe8zsonjY7wCvNbMfAZ8CXumet6JUIiKSN3XGqBuA3WZ2B/At4G3uvnum8zb1mqq7f4UwTSa77Z2Zx3cAzzy6c4fpMsMTE9wxHConvXxdGCpi46nhPttDrS5tJiKtlX4H01S3xAwOHAgPp8I+3xASEm1XGLjy006m2FMzj1EWMm9u8Yc6YpQDb423urQ7UUlERGRaebt4l9ugmhKED/kkpwzGbem7f0+81nzmEyovUA9VpL2qfwdT8ftCoTJdphSSCu1nPwv7lofpMzbyaEuaKJ1G66m2jFn4BX2ksIuRyaUAjO8P25YU4n+CKimJtFf2EkwKqjEb3+J6x75qVSVDP2X47twV7uPcU9/7Dy1orMj85TaoiojIwpayf/Mkt0G1WAjJSctKy9kVp7aNjca5bafFqUdjMXGpt1fDvyLtkH7vJicrCUqphu+xYT554dbb8KFQFS1VRfKRdx1+njt+Bqc1vbXSgfI2/FtXpDGzU8ysNz4+x8zebGYrmtoyERFZ9Ep+9Ld2qLen+jlgs5mdSigX+EXgk0DdS7U1msecsG66WBcXpVm6OlZfOXHD4Qer+INIe2R/91JiUnIoDDH5ppPLx03t/jwAhbHDj/Udw1qBZhHyJk+paYZ6g2rJ3SfN7BLgQ+7+ITP7YTMbNmuDSuMATDHF2FTYNrwzDAkPPLQDAF++POzoyu0ot0i+VM0HL8Qs3tIpp2CjIYPXB0JioR0Mc1Pp7YXhUHqwcNvdYV9VCcLC6z/c1GaLNEq90WbCzF4KXA68KG7rbk6TREREglLOxijqDaqvAl4H/Km732dmG4GPN69Zs0vzVCeZKm/r7YuJENVz2kolJSqJtELV71lp48awecsWSsccEzamhKU4Lc57+yhuenHYtqklrZQcyVvh2rqCaiwn+GYAM1sJDLp7W5eISNdUDxVGGZ0Kn2Qe2ROGlVbHX1a6Y2daAVWkNaryF2zf3rD51FMhrpFaHvbt7wegcMut+O7vAjD2n+HSTd9ftfUzu3QIp67C+B2lrqBqZt8GLorH3wLsNLPvu3vd9RBFRETmaqEO/y539/1m9hrgY+7+R2Z2WzMbNhuLs4GWlpZybF/4dHzaxXH+22PDGJLtD5+Mfdly9VZFmikN6VYnBY6H38nCHXdSOjEWyd8WKimVznxi2HfuH5YP73txk9sp0mT1RpouM1sHvAT49ya2R0REpCwti300t3aot6f6HsK6ct9395vM7GTgnuY1a3Zmoek7iw9xYHIFAGM/HQGg764tAJSe+uRwsOapijRX6qGOhN9Bi/epahJe4tG3fhaAgXc8F4Bi/wUA/NGmP2Z1b/gL+Obby6tuiSzcMoXu/lngs5nn9wKXNqtR9QmBss8H2B/nifdsiIlJfbGQfvqoUixqPVWRRqvxO1XYujU8uOfnANjG9eF5TzcD7wzrofpnvhO2ve1yAN59T2X4V6Sa5+yaar1lCh9jZt8ws9vj8yea2Tua2zQREZF8qXf49x+AtwF/D+Dut5nZJ4E/aVbDZjMVKyotKQ3wlJUhSWJ0S+iyDvxyqKxkMYXfV61SD1Wk0Wr8TvlgmNbG054Unv/z1wCwX302fOW/wsvOeVzY95nfBeBbf93Fuf/53ma3VvKojTV8j1a9QXWJu/+32WHd8MkmtEdERARYwNdUgV1mdgrhPWJmvwo81LRW1aEQE5UOFIa5cfdqAM49ELYtiZ+WPS1Srl6qSOPEJCQGBo7Y5UNrgEoSkr9wX7gvlbC1ywD4wm/tAeDiV4QiECcsq/wZuvE5off6jO/8RePbLTlkubumWm9QfQNhdZrTzWw7cB/wsqa1ag6mmGDXoZAwsWQodJ7tge0AeMr+BSUqiTRKjWDK3lA5yfaHwvgfveRdAFz+1TDUa1u3409/AgAXfzKsJlXYFK4enfqmymkUTKXaghz+jdm+55nZAFBw9wPNbZaIiEj+1FumsJcwheYkQiEIANz9PU1rWZ2uefw6/vbu+CR1QodWhfux8ImYri71UEWaxLZvC8u3ARTC34ZX/k1PeL7zEQD2fuBWVv5qnLN62kktbqHk2UId/v0iMEyo+zvWvObULxXUv+L2Pbzi2HCtpvuY+Hb2hSEo1sc5cgqoIo0Xh3z9+PXY1gfCtlJmbjiUi0Ks+udrW9w4WQhColK7WzE39QbV9e5+YVNbIiIiUmWhZv/+p5k9wd1/3NTWzEHK/n3e8pNY3ZOSkOKw9CknHX6w1lMVmb/R0XAfl2xjcBAA27kTu+d+AHzTSeH+hOPDvkfDa/yLVzL14zBhoPi4MAxsl2huqswuZx3VuoPqs4BXmtl9hOFfA9zdn9i0lomIiORMvUH1+U1txVEoeZg+M9BlbH009EL90FTYeShe9l2xsh1NE8mf6ZZugyOno6Wi+bFiGV7CTzs5bDtwMGz7eZjWxrq14b63h653XBtO9+HXh2Mb1nhZqNwX7vDvn7j7y7MbzOzjwMunOb7p3MMv+sd338yb1j0VgEPbw7al37slHPPCc8PBtebViUhFdTBNgXRiAh599PB9faEMaDnIlsD2hKSl0n+E373i710DgH/sLQDYKz7I1Pt/M2ybDAN6uiAj9cjbGmP1BtXHZZ+YWRF4auObIyIiUuELqadqZlcCfwD0m9n+tBkYJ1RYahuz8Dn3xSueyk2PhGHf377wOAD87FhJKX36VqKSSH1SMlJ3XEbRjMJNtwJQ+sWzwrY0VDwRFrWw4QP4wBIACr/8dAD8238a9r3ig+Elf/JKis85Pbyuq9jENyDSXjNGGnf/M3cfBP7c3ZfF26C7r3b3K1vURhERWYScMPx7tLd2qLdM4ZVmdjxwYvY17v7dZjVs9jaFb9lz1owxMRSGB0r37gLAnhG/nZavYQOReTuaGtelEqSko6r8Azt4gNI5zwyP0wLkaUpNnJXvywcrX297XGdjMowe+ad/B4Cud1yLXxOK/Npvfqj+tsmityCLP5jZe4HLgDuAmGKLA20LqscvewYAZ526nX+4JWQevnAqfPfLobRWJqPIQjZTMJ0p4C5ffvjzmOHrVsC2x0zeGExTUpKvDK+xAwfhwZ3hmPWxFOH98TWHwhrHpb//LQr/62/n8EZEYCGvUnMJcJq7d0SJQhERWfgWcpnCe4FuOqTuL8D2/TcC8NZvvokNA1WfZOLQ8Ixz70SkzPbsPuy5L4s9195e2BPWP6UnJi+NHgr3/WFqjQ8swdaGNY259a5wv2lDuF8SCu0Xnv0HTWm3SKeZLfv3Q4QPC48Ct5rZN8gEVnd/c3ObJyIii9lCG/69Od7fAlzX5LbMyYnLng3AXYd2s6x7DQDF00L1Fi/Gt5V6qJpOI5Ip1lA67L6wZQulk0NeQppSY4/Ea6RWqFRJ2r4j3Mdeqe3aUzl3ur562V8C4Nf/Ydhe1PQZmZ8FNfzr7v/UqobMVS9hXtxLjlvD9ljwZfu14Zf8uLOrgqjmqcpiVnUZxHaE4Ohr44fQtWsqwXTfvnBsyvAdO0Tp6z8CMlWSbrsqnPb628NpzzkVtj4c9u1+X3jdQExq0rCvzEMoU9juVsxNvdm/P+bIxQKGCT3ZP3H33Ue+SkREZH4W2vBvcj1hKs0n4/PLgCXADuBa4EUNb9ksegifhL+4fZhv/kW8zPvcMJ/O45JUSlSSRauUmfqeRmni70PqodquMK+briI2EueppkpKSW8fdkn4vZoa/lI4XW9PeNlLnlF+jZ37hw1+AyL5VG+0Oc/dn5J5/mMz+x93f4qZvawZDZvNWUtCduGavgL/75+HTvQfXBj/IKQ/IgqmstiVatSVmYqFGdIQL2CpkEMMqpYy6McnytdUbeuDYduqFeE+ZQNvfQhOCw/9i7HQWn/I+rXnvWv+70EWtbwN/9Z7obFoZk9PT8zsaUDKQJhseKtERGTRW7BlCoHXANeY2VJCwaL9wGvMbAD4s2Y1rpZbbvkfCoV+CoWQqPS+x7yFB0LxF2znI+FBX/iUXJ5rpx6rLFajo5Wf/+qEpVgQ3/uXlIvjl0d59uwL98uXVXqkQ6vC8bF4vj0YkpPo7cFv+euw7eKW/jmQRWBBrVKTuPtNwBPMbHl8PpzZ/ZlmNExERCRvZiv+8DJ3/4SZvbVqOwDu/oEmtq2mpz71Kdx8881sWHk+AF0GByfCoPvBq8ICyUv+4qRWN0ukPaar55u29/RUeqjxGBt9tPZrqPRey68/cBAfXBq3xdra43HJt198OwB+0wcofeM2AIpaZVkaKA3/5slsPdW0ZMVgjX1tuXychn8/8sTfB2B9/yire0I24tIrngRk/hNqJWmILCTTFHQ47D4+tgMHAPBUPD8GWxsZqTy+74Gwb/WKcGx/P4xVVSfdGWfQxeQke9pbKT6tMW9HpFreEpVmK/7w9/H+3dX7zOy3m9QmERERoE29t3mYTwbPW4G/blA75sQwPnJ/uKz7+QuG+do9sXh3TK6wqTgfLyVoqKKSLEC2fRu+7rjwZCIssXZET3Uyk5wfE/jK++LvhxcK5WHf0hmnHfY1Cg8/jJ3xusO2lXo+Eb5+A96DyEzCKjX5+kmbT6TJ1zsVERFpsvn0VNvaK99fCD3V6+/ewAWnbAsbB04BwLvDNdbyp/R4zVUkdyYnj5wSNhx+9n3V6vJi4uXrprF2rw8Nhe1dXZVKSvH3ojyVppiZWpMuXHWHz9nF1ZeE0+75yBGfngsb2lLvRRapBTX8a2YHqP2eDOivsb0lHOdJ3ScA8G8PTPKyr70g7Pj5ViDzR2NgoObrRXIjG1Bj1i19YR1TSqXKB8aUkZ+OT8cuWVIOuMXloZqo3/F3ABTisG5p52exn90Xtj0zJACWtoWKpDbyaGPfj8hcLLSC+u5eK+tXRESk6RbilJqOtW0sDHt97Nn7GXv3FwDou/R0IDP8O90cPpFOlXqY2SS7WKs39UYP+7me7mc8jtLY/mG8N/Rsp3Z/Puxbty7su+cj4fnyZfjaOFz8sbeE073ig+H5+vm/JZH58IXUU+1UhrG0EALnR396PH942T4AJr97DwCFp54ZDlQwlbyoDo7p+dRUJZimvy6xEL7t2Y0PhMIMNhIXEo/rohI/WHp//xG/B7YnrDvsq0LZweLqS2Bt3LmpQe9HZJHKZVAVEZHFwCjlbKJJU7tyZnahmd1lZlvM7O019v+Vmd0ab3eb2b65fo13vOVBKBgUjOJvPIfibzwHGxkJVWJE8mJiIty6ug6/ZfeZhdv4OIyPVy5zAG4F3ArQ2xtuXcVwA2zsULiNjmKjo/iqVfiqVRRXX0Jx9SWUdn2uHe9YpC7uR3+bzWwxKnPcpWbmZrZ5tnM2radqZkXgKuB8YBtwk5ld5+53pGPc/X9njn8T8ORmtUdERPKlmYlK9cSoeNwg8BbgxnrO28zh36cDW9z93tiwTwMXA3dMc/xLgT+q9+S7S+Ea0kNfm+K43wgdbl8bLwxlkzxA11als6RkJKj8rPbGakepzm6xWLnPXl+Fw3+e0/zUWEWM8VBZyQdD4r7t3Fm5drr+12s2pzB06VG+EZFcqzdG/THwPuBt9Zy0mUH1eGBr5vk24Bm1DjSzE4GNwDen2X8FcEV67jh7ijsB+PDtZ/DHXWGo13btCvtTcO3untcbEGmKNC7V21sJor1VJQSzyUnVyUtJoYClQhDp9SvjijKHDoVDNr26fHhp52fDsbHoQyrwINLJ5jlPdcjMbs48v9rdr46PZ41RZvYUYIO7f9nM2h5U5+Iy4F/dfarWzvhNuBrArJCzBGsRETla8/yDv8vdZ70OWouZFYAPAK+cy+uaGVS3Axsyz9fHbbVcBryh3hMbxmkeShL+8nHDMByH0wpV8/g0/CvNkMpfdnUd+TOW9mUXcaiucpQtdp+GebOvg8r28fFyL9b27gXiNBmAnp7KMm7pdWmt0/37w/PVlWYX1r54zm9VpJ1CQf2mnX62GDUIPB74dlxD/FjgOjO7yN2zvd/DNDPa3ARsMrONZtZDCJzXVR9kZqcDK4H/amJbREQkb+aR+VtH9u+MMcrdh919yN1PcveTgB8AMwZUaGJP1d0nzeyNwA1AEbjG3X9iZu8Bbnb31PjLgE+7z61uxkUbQtOHx3vw554JgB0IyUt+zLHhIPVQZT5S7zH9HFX3PLPF7quvd2Zr9lafJyslH6XXpzyAtL23F3sk5A/4qtjtTD3eycny6wopn2B1SEqy4f2zvz+RRWwOMWpOmnpN1d2/Anylats7q56/62jO3RVHeh8Z68Z2hD86pZM3ho3Vf7y0nqrMVfZnZroh3myZwOqgWipV1jhN0pBuMjFR2Va9/mlKPHIvV0cqB9w0xDsxDpMh+KZs33Im71Bd71Kk4zWz9m89MSqz/Zx6ztkpiUoiIiKHafI11abIbVC9/sHwnX7dpjH2X/UjAAbfH645e/V8PvVSZTrZpCOo9BgnJiq9xblIlbwGBmr3TLNfs7//yLmnqR1pqs3kJB57qLYzjMgU4nzT0o7PQE/YVz3XdGr4S+E1Y4eUoCS5lrOYmt+gOtQX/mA95TEPMnh+GOsqxeLiR/wxk8Wpekg2yQ7bTndNNFt0IQW8bNGGtL06KKfM3Kmpys9hCpxp+Daez/YPV4o1pCzeOL80rZlqY4fw/iVhW/VwMhxWqvCw5se1U0XyLm89VXXhREREGiSXPVXHuWHkNgA+dP4JMBiXworLX6XlsI5q+E4WjukSjabrwVarUcHoiPNUnzObGZyWYav+OYw9Vl+2/MivmXq+8d4Hl1HsvyBsG6xqzrEvqe99iOSUA56zVWpyGVRFRGRxyNvwby6DqmGc0/cEAP75z0v8xgdjTyD1GnRNdeGbS7WsWj3U6qkwM80zna6nWypVZphXT41JiUbZ16Vrouk1k5PlJQrTNdXCHT8Nz08J08MKy19UXppNhe9lMVJQbZH94yH546xjduM/ikNmp28K9+mPV1du357MZr4Z3dXDtUlKKpqcPDIxqPpDm/uRH+Cy561OVEoryqTLFL195SHcFDjtmb8f7rNfVsFUJDcUdUREpCM5mlLTMsOToRexc2QJpzw2ZHB4nJ7AYG7fltRruiSiepOQqqsjJdmeZ/VybNkhXUKPs5wUl6bbxKkwlEqVHmlMSLI9u8PzpTHjqKsL/2lYhapweljZMM0v1ZQYEcA1/CsiItIwnrO+am6D6mAxTEt40uO24SeeDoCvXFn7YNX+zbd6kpJq9VBn6s2mx+l6Z1oUPPs10pSYpGpqjA8uq3yNnlCEwbZtC/uOOw674+6wL17rt5FH43lCb7aw+hJKSz8Z9sVzqocqUqEyhS30C8eEpvccV8S27wDA164NO3uqqswooC4e2UBaK1s33VevClO9nmmpVNmXsnWrs3iLxfKwbyGWECydcELY1X8BpccMh5fHKkuFM14HVALo1O7PU4wlB0VkYchtUBURkYUvZx3V/AbV3WPh8/7YtikKP7wfAHvMKQB4b9W8VQ3/5kv1+qMzVURK29JQbUo0GhsLRe1rvR4qvc/qJKRUu3dsrDzdJiUclV+a6u0WCuVRkTTP1HY9EvZtoFxcvzw9pqqAUnH1JYjIzDT8KyIi0iCuoNoah6bCd3p8pMjA5tBDLaVeRvV0CRWByI/s9c70/1a9Skz2/zP9H6frn0lvb+U8KRkp+9uZEpPSMXF0w/aH66CMjJQTitLIh03ExcEPHgjN2vCySrWjqjq8pZ2fpbDp1bO+XRFZWHIYbQysi3Uxfn7zrg1cumZVeNKTGZaTzlNPFm+hcHhR+lqvy84trc7izQ4Np/NUVz1yP7LqVipgXwzPiye+onz41KGvhn1pOHh4f+Vchw6fu1pultYwFZk3B+qced4xchhURURksdA11aZz8EnOXBESU5688SEYXgGArQjDcp56K2k4WFqn1nzR6p7p5OSRy6hlXz9ddaTsa6qnyaTh3JSkNjk5fXWlzBCzHQi9To9DvTYVeqylHZ8pD+mWh3tTDd7MEmyFqikxqUKSxQpJIjIPrmuqLXPNz8JQ79t6V7L0Cz8CoPjOx4ed1dfLNBzcPLW+xzPND4Uw5JoeV2f61hrarZUFnLJ10/Bt+j9Pr3c/vDh+5jw2PFxZFWb54cO0Uwe+DEBx6IWVZsyhoL2CqUjj5HH4V9FGRESkQXLbU332MeHzwNCyEYp/8GthY+rJpMQU9VAbq975vtOtUVpr+3THZrfVGj5Ow7wp4Sgdc+hQuO/rq2QLpxKCu2NB+/5+bO/e8Pjnfxe+1Lp1ABRXXhye/+yjFE551UzvUkRaQMO/IiIiDZK34d/cBtVvPhSul732q+dh27cDUNqwIeycKflF5q5Wz3K6ZKLJydnnBc+UqDQ1Vbk+mj6iVhe9T8+zr0/XTdPSa9l2pN5rT5zL2tODL1kSXp4SjfZ+MZx69+cBKJ7yqsocVC0SLtIWjuM566rmNqj+ygnxwcQ4viquTlOd9KJAOnczZe9mg+F0mbWFQuX/Ic0bnilRKUnDuL29hxesh8ODaNpePT+1uv3d3eVkpvKQ7o7PVNoYA60/8A9h29BQODZTOlDBVKT98jalRlFHRESkQXLbU/2PB0Mv5iXf+G/8uU8PGweX1T5YPdaK6ZJ/ag3xpuHTWj3M6vvUu8yWC5ypIlL1188Wwk/niAXpjxhO7u2tFNBPveGUlFRjEYWp0RsOa5vt2Y0vC1NqSscdF7bFpdtYjYh0kJx1VPMbVEVEZGHTIuUt9LrHhCo3k/cPU5ysmuRf3cNST7ViLt+LbCGG6tdXf6+z1zinm9KUTTiKPVvbE6e5rFl75GvS0m1V02bs4R3lnuZhU2ig8rUnJsptLPZfELalAlu1eqODNbaJSHu5gmrLfGdnGOo9/f5HGKxePzVZrMG0nvVHq5O6klqZudnX1wq0Wd3dlSCYXledvZd57kNrwoPs8HF1JaQkBszya7Kqv1bmfaSM3nK5wUyxfBGRRsptUBURkYXPc3ZVNbdB9ds7QqLKbx4qVJJWUgH9dL9Yh3/r6bHXqrULYTi3ev3S1HMsFI5ct7RWRaQ0nzSpXge1UDhyObY02jA1VWlT9etiL7Rw1934cceGTSk5LRXIT5WSVq4sbytPk1ESkkiu6JpqSxhYgTEPf+hXv/RYfHn8w1q9nupCDqa1hnhrFZ7PPp9pDmqtzNw0lJoC6dRUZZg2qQ6gpdKRmcDV7Rgfr/xfpeCaPhiVSpV96TppCpgjB8P9mW/C45zTFEQLx10WmjgeizcMPP/I9yoiuZOz2g95DKoiIrJYlDT822wOXuKT58Ws0ac+t9LLWRpTOOtZ0zOvZhrSnq6AfZJdhzSprkhUKBxZFjD7mtT7TEuvVc9FHRioDNtWtzW9ttb/T63EqdRDHX007FpbWabN4xB/cfmLDjtNGurNrocqItIqOQyqIiKyWGj4t+nCNdUDB8P1tjUA3fEaXLZ+bLWFlrRU3bOrNW2mujLS+HilF1qdKJS2l0pH9iizvdnqxcWrC9mPjVWuiUYWKyOlnuPU2Jcqr4vzTK286HgRJkJPN/VMS2Ofq373R/RQy29j+Ethv3qpIrmXx0XKcxhUw/Dvtx8KcxWP//Pr6b0y/oFNw4615q0ulGA60/uYrth9KveX/bCRjq1OPCpksqlTME4B2P3I8oDpmFQCcN9evBi2mYd2+OCRlRVsLATTFDinDnw57JicLBfAT9uKcyhsP12wFZF80io1IiIijaCKSq0Qhn9f/OT7AOh7yePxQkyomW45sLz3UrND19MlI820Zmy2IH1Vyb/UC7U9e4A4vzOVB0y90lQecORgpRcap7ek5dFSr9K7K0O/3tUTzx2TyrZeHZ6vWon3huHi8vqlmSXXkuLgC2u/HxGRDpXDoCoiIotBuKaar65qDoNquKZ6/wNhYfIndnVBKqg/GJNlqgsS5M1MSVXV1Y6yvfPqQg4p+SddEy2VKr3W9D2KvXpfHgrU2+7d0BOuj6beZGqPd/dUHlusq7v3i+FLpOuge79Y/hqpp5kKMhQ2vCx8jdm/AyIigLJ/WyAM/+4+FP7g+/Hr8JSAk4JRdWZrdl8nDwVPN7Rbq6Rg9Uo83d1HVk6qfq9jY9MXy0/3Pd3lYFpOJlpemR9aDqJxuDY9LysUjhy27eTvuYh0LMdz11PVXzsREZEGyWFPNQz/Pu1x2wGwkVMqw5X1DJt2sunWKs0O46b3mBKOsmuXpqkzcbpL6mmWh3G7uso1cctTWNLXTF9rYrw8LSXN+cxKy6exMn75OOybFJe/iNKuMK80JTFVHyMiUi8N/4qIiDRI3oZ/cxhUwzXVa/5zEwBvWr2qPM2j3IurlajUqddUs+2abuHw7DXi7DJsUPkYVyrB4OG1jwvx2mYpruhSOPYllHZ+NhyzInY107SZqDB0aaXoQuqxZpKRUrLRTApzKNYgIjKdsPSbgmqTheHfJywPRdZt5yP48ceHXV11vJ1OC661qj7VqoBU63ioZAFD+f2n5dCmlofgaPE9Tw1/CVbFRUXTkHJaczQO0ZZ2fe6ICkYavhWRdsnbIuUdEllERETyL4c91VhQfzI0vXTMMZWEnJ64WHl2SBQ6qwZwrWXPqlX3UNP7KRYrw7/VdY4nJso9VF8ZhnbLVY/SAt7DX8J27Ajb1v96eF0snpQdIhYR6RQqqN8iL3r5IwDY1m2UNp4UNsYVT8orptTS7uHf6TJ8s8O405QSZGKifJzFa6GFeN2z9NA/Udh4+WFfqrTrYwBMjVxf/popmJa2fiK8PhVk2LcvHHPsUb8zEZGGUkUlERGRhnGtUtN8IVHpAx8OyUlvfelxlV5f1TqeM85XbWWPtVZB/DSMm3qq2R+czJDuYYrFci+8kMoCpl7o0FC590l/fzjmxFcc3owHPwIxT6k6i9dOv2KOb0pEpPny1lNVopKIiEiD5LCnGhKVNq8MU2rcCpUeanWvM9srbVQPtZ7Xp2Oqe9Cl0uG1erPHmFWOqy6EH3u1xYHnMzV6QzhVnG9auONuAPzUjbPOIS1sevWM+0VEOomuqVYxswuBDwJF4B/d/b01jnkJ8C7C9+9H7v7rs5+5wHPeFIZGfWoSn6wqtZddlQUaO8Q73bmygbu69F8247f6mGRsrDIknI6vmnc7deDLWJzDWs7SXRvutPKLiCxE3sT839lilJm9FXgNMAk8Avymu/98pnM2LaiaWRG4Cjgf2AbcZGbXufsdmWM2AVcCz3T3vWa2tlntERGRvGneKjX1xCjgh8Bmd3/UzF4PvB/4tZnO28ye6tOBLe5+L4CZfRq4GMg2+LXAVe6+F8Ddd9Z36hK+O/TYvLvnyN3V2WLZXmR2G9Tfi53u+JnmnVb3OEulSrWkgThBNA311mhHed5pKj84Pq55pCIijTFrjHL3b2WO/wEwa53WZiYqHQ9szTzfFrdlPQZ4jJl938x+ELviIiIi5WuqR3ubRT0xKuvVwPWznbTdiUpdwCbgHGA98F0ze4K778seZGZXAHHOh4GXuOuLIdHntEtGK0u/pUSf6oL6jVgKbrrjswlQ0y0SnpKRpqYq+1KPNduLjcfbgbC8WuqhHrHot4jIIlGa3zXVITO7OfP8ane/eq4nMbOXAZuB58x2bDOD6nZgQ+b5+rgtaxtwo7tPAPeZ2d2EIHtT9qD4TbgawKzgAG/+7yUA/Ed/fyUw1ZP9Oxe1EoyqA2atOajVCUrp2KkpbCJURCqvrFN9fsDTPNV6FggQEVmwHLd5BdVd7r55mn31xCjM7Dzg/wDPcfex2b5gM4d/bwI2mdlGM+sBLgOuqzrmC4ReKmY2RBgOvreJbRIRkZxo8vDvrDHKzJ4M/D1wUb05P03rCrn7pJm9EbiBkK58jbv/xMzeA9zs7tfFfc8zszuAKeBt7r67nvO/+wmZXuBsvchaqvfN1JPN9kJn6g1XnzMO45a3Dw7ig7Hof7bWbzxPceD54fHA9E0REZH5qzNG/TmwFPishcuKD7j7RTOd1/JWV9Gs4AXrY+LBawHwgYHKNctYnq9sujmhtY6pZaagXE/gTlJwHRysLAqe2hwVV15cKeiw9sWzn1NEpAOY2S0zDLHOy0DXWj9j8FeP+vU37/tw09o2HV20ExGRDuVNLf7QDLkNqh8+/04AXn/9Jnz58rBxLr3uufQ0s8O/Sa1M36repx2MWbwxKcn27Mb7Q4JVMRbEP+zLqIcqIlLmQGl+iUotl9ugKiIiC988p9S0XG6D6uu/cAIA3t9/ZK+zuvYvzK0SUrVsD7SeaTtpybbJUMvX4tey79+Cn/vMw5uh66giIgtGboPqYUGxen5oGgZOwXUmtYaBqzN965njWihUkpBiOzwmTqW5qXbJe6lukYKpiMh0XD1VERGRRnCau0pNM+Q3qGaXV6un2tF0Zuqh1lNRKRkeLj+0sUNx2/5w6CmvmumdiIhITU6JqXY3Yk6aWVFJRERkUcltT/UHrwyr8zzjumdVqhP19YX76oL6MHuvtVbiUq1jUxJSdyjiXy7ssGRJeam2wnGXhW1DM70DERGZjYZ/W+TsPworuJRg+tVhsolK081LTclNY2OVQJnUGhpO50zBNa6LWrj7HuyJbwDA/+eDANhT3jKXtyQiIhmOa56qiIhIo+Ttmmpug6pvDCv22NhYqP8LR/ZQ66ndm+agFothvdPZjo/TZorLXxS+xNZPhHbEXiqohyoi0hj5K1OoRCUREZEGyV1P1ayLrq6V5V6oZ6+Dpl5n9fXPbMLRTDV/q4+vdUzsFU+NXB9esuFlc34PIiIyOwdKruHfpnJ3Sj7O7nd8H4DVV72wshRtdQWkVFmpVsJRdfH9YvHIhKe0q+95la9/x98BYGe8bj5vQ0REZpW/4d/cBVUREVk8XIlKzTZFaWqEoQvCMKyPT0BcWq08Paa6FvBM0pzWiYnKlJqYsGQjB8PTwtfLhxfVQxURaRHV/m2ZqR0h4BUKhZlXjoH6Cutnhn/vuujLAJz25YvCrp7z5t9gERFZ8HIbVEVEZGFTQf2WMLAuCi89JzwtlcpLq3lv3+GHZnuw1UlLqfeaSViyA6EA/hlf+5tGN1pERObMcWX/ioiINEberqnmrviDWZHuruX4Z7+Df/Y70FXErYBbIfRCa80tda/sKxYr1ZOmpsrbi/0X4ANL8YGlrX9TIiKyIOSup+o+yfjELgq/9PjwfHg/tnJFeJwOSoE1FYMoFI7MBE7Dv5nShMWB5zen0SIichRcU2pEREQawQH3fA3/5jCoGmbd+K0/C0+f/8z6XpZ6rem+p+fw5yIi0mE0T1VERKQxHGX/Np+DT2KbjgvPvITHikpHTK3J1gI+dCgcMxV6ph73pSXcRERE5iuHQbVIoTgAa1eHp6VSJVBaVSWlGDht9NFyoHXCsG9x8IUATA1/KTxXcBUR6TAqqC8iItIQSlRqiRKl0ij+f28LT1/4rEyVpMN7qjYWhny9f0k5Ianw8MPhmNPjS9RDFRHpUJpS0zIT9x4AoBuOLKhfXsA8DPXayAh0hXmpdvoVrWqiiIjMU956qrmrqCQiItKpcthTdfASPZuPDc+mJmEkDO3aQFhjlckwXOC9veG+vx/bPwzA1O7PA1BcfUkrGy0iIkchbz3VHAZVERFZDFzFH1ohLP3GysHwtLsH4pQaxicA8NhjTfNWR6/8AgN/9/GWt1REROYnbz3VHF5TDcUfykZG4NAYHBrDe3vx3l5sZAQbGSmvXvPR753avuaKiMiikcOeqoiILAquRcpbwnHYtgsAO3YIHxoKjyfC8G+aYlP4+QMAvP7yB1rfSBERmTdVVBIREWkIz9011RwG1QKFQi+csCY+LUCsnJQSlejpBsBPWA9A8W1vaXUjRURknlSmsCXiJ5eSh6eFAjYcqiv5yuVhW1q1ZkcsSTjU6jaKiMhilMOgKiIii4WuqbbKWFw7tVjEeuK2WOuXOD/1wF/+AIDBX7wT+80PtbqFIiIyL7qm2nRmRbqKg3BgNDwfG4Ou2m9j2Uc/1sqmiYhIg+UtqOaw+IOIiEhnyl1PNUwGnoRjV4XnJceXLgXA9u0LhwwsaVPjRESkcRx0TVVERKQBPH/Dv7kLqiu61nD+itcw9b17ACg+93GwPBbXnww1gQsbXtau5omISIM4yv5tuv2lfXzt0HUUH3tB2NDbg217KDweWtW+homISIPlL/tXiUoiIiINkrue6lRpggOHtkMpfnqZmMTXrwPAbr0zbDutTY0TEZEG0yo1IiIiDZC/4d/cBVWzAt3FpTAaqiZRKlUK6Q/0t69hIiLSBAqqTeaUfBL6wko0dBWxNBR83Nr2NUtERBrMIWc9VSUqiYiINEjueqqGUSz0wIpQRYmSw70PAPDe/x16r1f+tF2tExGRRnK83U2Yk6b2VM3sQjO7y8y2mNnba+x/pZk9Yma3xttrmtkeERHJm9I8bjOrI0b1mtm/xP03mtlJs52zaT1VMysCVwHnA9uAm8zsOne/o+rQf3H3N9Z73sHCKs5Z8lLYExYmp68HJsM378qfvrMRTRcRkU7hzemp1hmjXg3sdfdTzewy4H3Ar8103mb2VJ8ObHH3e919HPg0cPF8T3rqcZP823t2QX9PuC0dgBOPCzcREZH61BOjLgb+KT7+V+C5ZmYznbSZQfV4YGvm+ba4rdqlZnabmf2rmW1oYntERCRXfF7/ZlFPjCof4+6TwDCweqaTtjtR6UvAp9x9zMz+F+ETwbnVB5nZFcAV8elY8Y1/f3vt09U9itwOQ8CudjdijvLYZshnu/PYZshnu/PYZujcdp/YxHPfAJND83h9n5ndnHl+tbtfPd9GzaSZQXU7kO15ro/bytx9d+bpPwLvr3Wi+E24GsDMbnb3zY1tavPlsd15bDPks915bDPks915bDPkt93z4e4XNvH0s8aozDHbzKwLWA7sZgbNHP69CdhkZhvNrAe4DLgue4CZrcs8vQi4s4ntERERSWaNUfH55fHxrwLfdJ85c6ppPVV3nzSzNwI3AEXgGnf/iZm9B7jZ3a8D3mxmFwGTwB7glc1qj4iISFJnjPoI8HEz20KIUZfNdl6bJeh2HDO7otlj4s2Qx3bnsc2Qz3bnsc2Qz3bnsc2Q33YvNrkLqiIiIp1KtX9FREQaJFdBdbaSUu1iZteY2U4zuz2zbZWZfc3M7on3K+N2M7O/ie/hNjN7SpvavMHMvmVmd5jZT8zsLTlpd5+Z/beZ/Si2+91x+8ZYRmxLLCvWE7fPucxYE9teNLMfmtm/56jN95vZj2MZ0Zvjto7+GYltWRHnvv/UzO40s7M7ud1mdppVyrXeamb7zey3O7nNUltugqpVSko9HzgDeKmZndHeVpVdC1Snfr8d+Ia7bwK+EZ9DaP+meLsC+HCL2lhtEvgddz8DOAt4Q/x+dnq7x4Bz3f1JwJnAhWZ2FqF82F+5+6nAXkJ5MciUGQP+Kh7XLm/h8Az3PLQZ4Jfc/czMdI5O/xkB+CDwH+5+OvAkwve9Y9vt7nfF7/GZwFOBR4HPd3KbZRrunosbcDZwQ+b5lcCV7W5Xpj0nAbdnnt8FrIuP1wF3xcd/D7y01nFtbv8XCTUwc9NuYAnwP8AzCJPiu6p/VgiZfWfHx13xOGtDW9cT/iieC/w7YJ3e5vj17weGqrZ19M8IYS7hfdXfs05vd+brPw/4fp7arFvllpueKvWXPewUx7j7Q/HxDuCY+Ljj3kccXnwycCM5aHccRr0V2Al8DfgZsM9DGbHqts25zFiT/DXwe1SWzlhN57cZwIGvmtktFiqbQef/jGwEHgE+Gofb/9HMBuj8dieXAZ+Kj/PSZonyFFRzy8NHyY5MszazpcDngN929/3ZfZ3abnef8jBMtp5QFPv09rZoZmb2y8BOd7+l3W05Cs9y96cQhhvfYGbPzu7s0J+RLuApwIfd/cnACJVhU6Bj2028rn4R8NnqfZ3aZjlcnoJqPSWlOsnDFitGxfudcXvHvA8z6yYE1H9293+Lmzu+3Ym77wO+RRg6XWGhjBgc3rZyu63OMmNN8EzgIjO7n7ASxrmEa36d3GYA3H17vN9JuMb3dDr/Z2QbsM3db4zP/5UQZDu93RA+vPyPuz8cn+ehzZKRp6BaT0mpTpItb3U54Zpl2v6KmL13FjCcGd5pGTMzQrWQO939A5ldnd7uNWa2Ij7uJ1wHvpMQXH81Hlbd7jmVGWs0d7/S3de7+0mEn9tvuvtv0MFtBjCzATMbTI8J1/pup8N/Rtx9B7DVzE6Lm54L3EGHtzt6KZWhX8hHmyWr3Rd153IDXgDcTbiG9n/a3Z5Muz4FPARMED4lv5pwDewbwD3A14FV8VgjZDH/DPgxsLlNbX4WYSjpNuDWeHtBDtr9ROCHsd23A++M208G/hvYQhg6643b++LzLXH/yW3+WTkH+Pc8tDm270fx9pP0O9fpPyOxLWcCN8efky8AKzu93cAAYURieWZbR7dZtyNvqqgkIiLSIHka/hUREeloCqoiIiINoqAqIiLSIAqqIiIiDaKgKiIi0iAKqiKzMLOpuHLIj8zsf8zsF2Y5/iTLrFhUte/bZra51j4Ryb+u2Q8RWfRGPZRFxMwuAP4MeE5bWyQiHUk9VZG5WUZYpi2tafnnZna7hTVHf636YDPrN7NPxzU9Pw/0Z/YdNLM/jT3gH5jZMXH7GjP7nJndFG/PjNufk1lv84dmNmhm68zsu3Hb7Wb2i635NohILeqpisyuP66K00dYfuvcuP1XCJV7ngQMATeZ2XerXvt64FF3f6yZPZGwVF0yAPzA3f+Pmb0feC3wJ4S6wH/l7t8zsxMIS8E9Fvhd4A3u/v24EMIhwlqaN7j7n8Y1h5c0+L2LyBwoqIrMLjv8ezbwMTN7PKHU46fcfYpQ+Pw7wNMIpfGSZwN/A+Dut5lZdt84YW1VgFsIdYwBzgPOCOWZAVgWg+j3gQ+Y2T8D/+bu28zsJuCauDjCF9z91ga+bxGZIw3/isyBu/8XoVe6pgGnm/BKndApKh9yC8BZ7n5mvB3v7gfd/b3AawhDyN83s9Pd/buEwL0duNbMXtGAdonIUVJQFZkDMzsdKBIKn/9f4NfioulrCMHtv6te8l3g1+NrH09YEGA2XwXelPmaZ8b7U9z9x+7+PsKqTaeb2YnAw+7+D8A/EpY4E5E20fCvyOzSNVUIq4Nc7u5TMfHobMIqLg78nrvvMLOTMq/9MPBRM7uTsERdPQuVvxm4Kg4VdxEC8+uA3zazXwJKhFVjricsJfc2M5sADgLqqYq0kVapERERaRAN/4qIiDSIgqqIiEiDKKiKiIg0iIKqiIhIgyioioiINIiCqoiISIMoqIqIiDSIgqqIiEiD/P/OBP97jGIZvQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ribs.visualize import grid_archive_heatmap\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "grid_archive_heatmap(archive, vmin=0.0, vmax=1.0)\n",
    "plt.title(\"LSI MNIST\")\n",
    "plt.xlabel(\"Boldness\")\n",
    "plt.ylabel(\"Lightness\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we display a grid of digits generated from a selected set of latent vectors in the archive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see below, digits get bolder as we go along the x-axis. Meanwhile, as we go along the y-axis, the digits get brighter. For instance, the image in the bottom right corner is grey and bold, while the image in the top left corner is white and thin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/pyribs/lib/python3.7/site-packages/ipykernel_launcher.py:33: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'index' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yp/6z86mmwj6ys7n5xdcbd57cqc0000gn/T/ipykernel_38899/3465062011.py\u001b[0m in \u001b[0;36mshow_grid_img\u001b[0;34m(x_start, x_num, x_step_size, y_start, y_num, y_step_size, archive, figsize)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0msol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_to_int_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yp/6z86mmwj6ys7n5xdcbd57cqc0000gn/T/ipykernel_38899/666924021.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_grid_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m105\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/yp/6z86mmwj6ys7n5xdcbd57cqc0000gn/T/ipykernel_38899/3465062011.py\u001b[0m in \u001b[0;36mshow_grid_img\u001b[0;34m(x_start, x_num, x_step_size, y_start, y_num, y_step_size, archive, figsize)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0msol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_to_int_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"There is no solution at index {index}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'index' referenced before assignment"
     ]
    }
   ],
   "source": [
    "show_grid_img(10, 8, 7, 105, 6, 15, archive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we display images from a wider range of the archive. Note that in order to generate images with high boldness values, CMA-ME generated images that do not look realistic (see the bottom right corner in particular)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_grid_img(10, 8, 15, 90, 6, 15, archive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine how realistic all of the images in the archive are, we can evaluate them with the discriminator network of the GAN. Below, we create a new archive where the objective value of each solution is the discriminator score. BCs remain the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_archive = GridArchive(\n",
    "    solution_dim=generator.nz,\n",
    "    dims=[200, 200],  # 200 bins in each dimension.\n",
    "    ranges=[(0, 784), (0.5, 1)],  # Boldness range, lightness range.\n",
    ")\n",
    "\n",
    "# Evaluate each solution in the archive and insert it into the new archive.\n",
    "for elite in archive:\n",
    "    # No need to normalize to [0, 1] since the discriminator takes in images in\n",
    "    # the range [-1, 1].\n",
    "    img = generator(\n",
    "        torch.tensor(elite.solution.reshape(1, generator.nz),\n",
    "                     dtype=torch.float32,\n",
    "                     device=device))\n",
    "    obj = discriminator(img).item()\n",
    "    discriminator_archive.add(elite.solution, obj, elite.measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can plot a heatmap of the archive with the discriminator score. The large regions of low score (in black) show that many images in the archive are not realistic, even though LeNet-5 had high confidence that these images showed the digit eight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "grid_archive_heatmap(discriminator_archive, vmin=0.0, vmax=1.0)\n",
    "plt.title(\"Discriminator Evaluation\")\n",
    "plt.xlabel(\"Boldness\")\n",
    "plt.ylabel(\"Lightness\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "By searching the latent space of an MNIST GAN, CMA-ME found images of the digit eight that varied in boldness and lightness. Even though the LeNet-5 network had high confidence that these images were eights, it turned out that many of these images were highly unrealistic --- when we evaluated them with the GAN's discriminator network, the images mostly received low scores.\n",
    "\n",
    "_In short, we found that large portions of the GAN's latent space are unrealistic_. This is not surprising because during training, the GAN generates fake images by randomly sampling the latent space from a fixed Gaussian distribution, and some portions of the distribution are less likely to be sampled. Thus, we have the following questions, which we leave open for future exploration:\n",
    "\n",
    "- How can we ensure that CMA-ME searches for realistic eights?\n",
    "- While searching for realistic eights, can we also search for other digits at the same time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citation\n",
    "\n",
    "If you find this tutorial useful, please cite it as:\n",
    "\n",
    "```text\n",
    "@article{pyribs_lsi_mnist,\n",
    "  title   = {Illuminating the Latent Space of an MNIST GAN},\n",
    "  author  = {Yulun Zhang and Bryon Tjanaka and Matthew C. Fontaine and Stefanos Nikolaidis},\n",
    "  journal = {pyribs.org},\n",
    "  year    = {2021},\n",
    "  url     = {https://docs.pyribs.org/en/stable/tutorials/lsi_mnist.html}\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyribs]",
   "language": "python",
   "name": "conda-env-pyribs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
