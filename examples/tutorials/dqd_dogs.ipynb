{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cr-94yAuzYns"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJZEFUAfXX2z"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade torch==1.9.1+cu111 torchvision==0.10.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git\n",
    "!git clone https://github.com/openai/CLIP\n",
    "!pip install -e ./CLIP\n",
    "!pip install einops ninja\n",
    "!curl -LO 'https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan2/versions/1/files/stylegan2-ffhq-1024x1024.pkl'\n",
    "\n",
    "!git clone https://github.com/icaros-usc/pyribs.git\n",
    "!pip install ./pyribs[all]\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./CLIP\")\n",
    "sys.path.append(\"./stylegan2-ada-pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYIf5bwsYPI3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import clip\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from einops import rearrange\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from ribs.archives import CVTArchive, GridArchive\n",
    "from ribs.emitters import GradientAborescenceEmitter, EvolutionStrategyEmitter\n",
    "from ribs.schedulers import Scheduler\n",
    "from ribs.visualize import grid_archive_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-RMRh5kXS8h"
   },
   "outputs": [],
   "source": [
    "def tensor_to_pil_img(img):\n",
    "    img = (img.clamp(-1, 1) + 1) / 2.0\n",
    "    img = img[0].permute(1, 2, 0).detach().cpu().numpy() * 255\n",
    "    img = Image.fromarray(img.astype('uint8'))\n",
    "    return img\n",
    "\n",
    "def norm1(prompt):\n",
    "    return prompt / prompt.square().sum(dim=-1, keepdim=True).sqrt()\n",
    "\n",
    "def spherical_dist_loss(x, y):\n",
    "    x = F.normalize(x, dim=-1)\n",
    "    y = F.normalize(y, dim=-1)\n",
    "    return (x - y).norm(dim=-1).div(2).arcsin().pow(2).mul(2)\n",
    "\n",
    "def cos_sim_loss(x, y):\n",
    "    x = F.normalize(x, dim=-1)\n",
    "    y = F.normalize(y, dim=-1)\n",
    "    return (x - y).norm(dim=-1).div(2).arcsin().mul(2)\n",
    "\n",
    "def prompts_dist_loss(x, targets, loss):\n",
    "    distances = [loss(x, target) for target in targets]\n",
    "    return torch.stack(distances, dim=-1).sum(dim=-1)\n",
    "\n",
    "class MakeCutouts(torch.nn.Module):\n",
    "    def __init__(self, cut_size, cutn, cut_pow=1.0):\n",
    "        super().__init__()\n",
    "        self.cut_size = cut_size\n",
    "        self.cutn = cutn\n",
    "        self.cut_pow = cut_pow\n",
    "\n",
    "    def forward(self, x):\n",
    "        sideY, sideX = x.shape[2:4]\n",
    "        max_size = min(sideX, sideY)\n",
    "        min_size = min(sideX, sideY, self.cut_size)\n",
    "        cutouts = []\n",
    "        for _ in range(self.cutn):\n",
    "            size = int(torch.rand([]) ** self.cut_pow * (max_size - min_size) + min_size)\n",
    "            offsetx = torch.randint(0, sideX - size + 1, ())\n",
    "            offsety = torch.randint(0, sideY - size + 1, ())\n",
    "            cutout = x[:, :, offsety:offsety + size, offsetx:offsetx + size]\n",
    "            cutouts.append(F.adaptive_avg_pool2d(cutout, self.cut_size))\n",
    "        return torch.cat(cutouts)\n",
    "\n",
    "make_cutouts = MakeCutouts(224, 32, 0.5)\n",
    "\n",
    "class CLIP(object):\n",
    "    def __init__(self, device='cpu'):\n",
    "        self.device = device\n",
    "        clip_model_name = \"ViT-B/32\"\n",
    "        self.model, _ = clip.load(clip_model_name, device=device)\n",
    "        self.model = self.model.requires_grad_(False)\n",
    "        self.model.eval()\n",
    "        self.normalize = transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "                                              std=[0.26862954, 0.26130258, 0.27577711])\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def embed_text(self, prompt):\n",
    "        return norm1(self.model.encode_text(clip.tokenize(prompt)\n",
    "               .to(self.device)).float())\n",
    "\n",
    "    def embed_cutout(self, image):\n",
    "        return norm1(self.model.encode_image(self.normalize(image)))\n",
    "\n",
    "    def embed_image(self, image):\n",
    "        n = image.shape[0]\n",
    "        cutouts = make_cutouts(image)\n",
    "        embeds = self.embed_cutout(cutouts)\n",
    "        embeds = rearrange(embeds, '(cc n) c -> cc n c', n=n)\n",
    "        return embeds\n",
    "\n",
    "class Generator(object):\n",
    "\n",
    "    def __init__(self, device='cpu'):\n",
    "        self.device = device\n",
    "        model_filename = 'stylegan2-ffhq-1024x1024.pkl'\n",
    "        with open(model_filename, 'rb') as fp:\n",
    "            self.model = pickle.load(fp)['G_ema'].to(device)\n",
    "            self.model.eval()\n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad_(False)\n",
    "        self.init_stats()\n",
    "        self.latent_shape = (-1, 512)\n",
    "\n",
    "    def init_stats(self):\n",
    "        zs = torch.randn([10000, self.model.mapping.z_dim], device=self.device)\n",
    "        ws = self.model.mapping(zs, None)\n",
    "        self.w_stds = ws.std(0)\n",
    "        qs = ((ws - self.model.mapping.w_avg) / self.w_stds).reshape(10000, -1)\n",
    "        self.q_norm = torch.norm(qs, dim=1).mean() * 0.1\n",
    "\n",
    "class Classifier(object):\n",
    "\n",
    "    def __init__(self, gen_model, class_model, celebrity_id='Lopez'):\n",
    "        self.device = gen_model.device\n",
    "        self.gen_model = gen_model\n",
    "        self.class_model = class_model\n",
    "        self.measures = []\n",
    "        if celebrity_id == 'Beyonce':\n",
    "            self.init_objective('A photo of the face of Beyonce.')\n",
    "            self.add_measure('A small child.', 'An elderly person.')\n",
    "            self.add_measure('A person with short hair.', \n",
    "                             'A person with long hair.')\n",
    "        elif celebrity_id == 'Cruise':\n",
    "            self.init_objective('A photo of the face of Tom Cruise.')\n",
    "            self.add_measure('A small child.', 'An elderly person.')\n",
    "            self.add_measure('A person with short hair.', \n",
    "                             'A person with long hair.')\n",
    "        elif celebrity_id == 'Lopez':\n",
    "            self.init_objective('A photo of the face of Jennifer Lopez.')\n",
    "            self.add_measure('A small child.', 'An elderly person.')\n",
    "            self.add_measure('A person with short hair.', \n",
    "                             'A person with long hair.')\n",
    "        elif celebrity_id == 'Musk':\n",
    "            self.init_objective('A photo of the face of Elon Musk.')\n",
    "            self.add_measure('A small child.', 'An elderly person.')\n",
    "            self.add_measure('A person with short hair.', \n",
    "                             'A person with long hair.')\n",
    "        elif celebrity_id == 'Zuckerberg':\n",
    "            self.init_objective('A photo of the face of Mark Zuckerberg.')\n",
    "            self.add_measure('A small child.', 'An elderly person.')\n",
    "            self.add_measure('A person with short hair.', \n",
    "                             'A person with long hair.')\n",
    "        else:\n",
    "            print('The celebrity \\\"{}\\\" is not a valid option.'.format(celebrity_id))\n",
    "            exit(0)\n",
    "\n",
    "    def init_objective(self, text_prompt):\n",
    "        texts = [frase.strip() for frase in text_prompt.split(\"|\") if frase]\n",
    "        self.obj_targets = [self.class_model.embed_text(text) for text in texts]\n",
    "\n",
    "    def add_measure(self, positive_text, negative_text):\n",
    "        texts = [frase.strip() for frase in positive_text.split(\"|\") if frase]\n",
    "        negative_targets = [self.class_model.embed_text(text) for text in texts]\n",
    "        \n",
    "        texts = [frase.strip() for frase in negative_text.split(\"|\") if frase]\n",
    "        positive_targets = [self.class_model.embed_text(text) for text in texts]\n",
    "        \n",
    "        self.measures.append((negative_targets, positive_targets))\n",
    "\n",
    "    def find_good_start_latent(self, batch_size=16, num_batches=32):\n",
    "        with torch.no_grad():\n",
    "            qs = []\n",
    "            losses = []\n",
    "            G = self.gen_model.model\n",
    "            w_stds = self.gen_model.w_stds\n",
    "            for _ in range(num_batches):\n",
    "                q = (G.mapping(torch.randn([batch_size, G.mapping.z_dim], device=self.device),\n",
    "                    None, truncation_psi=0.7) - G.mapping.w_avg) / w_stds\n",
    "                images = G.synthesis(q * w_stds + G.mapping.w_avg)\n",
    "                embeds = self.class_model.embed_image(images.add(1).div(2))\n",
    "                loss = prompts_dist_loss(embeds, self.obj_targets, spherical_dist_loss).mean(0)\n",
    "                i = torch.argmin(loss)\n",
    "                qs.append(q[i])\n",
    "                losses.append(loss[i])\n",
    "            qs = torch.stack(qs)\n",
    "            losses = torch.stack(losses)\n",
    "            print(losses)\n",
    "            print(losses.shape, qs.shape)\n",
    "            i = torch.argmin(losses)\n",
    "            q = qs[i].unsqueeze(0).requires_grad_()\n",
    "\n",
    "        return q.flatten()\n",
    "\n",
    "    def generate_image(self, latent_code):\n",
    "        ws, _ = self.transform_to_w([latent_code])\n",
    "        images = self.gen_model.model.synthesis(ws, noise_mode='const')\n",
    "        return images\n",
    "\n",
    "    def transform_to_w(self, latent_codes):\n",
    "        qs = []\n",
    "        ws = []\n",
    "        for cur_code in latent_codes:\n",
    "            q = torch.tensor(\n",
    "                    cur_code.reshape(self.gen_model.latent_shape), \n",
    "                    device=self.device,\n",
    "                    requires_grad=True,\n",
    "                )\n",
    "            qs.append(q)\n",
    "            w = q * self.gen_model.w_stds + self.gen_model.model.mapping.w_avg\n",
    "            ws.append(w)\n",
    "\n",
    "        ws = torch.stack(ws, dim=0)\n",
    "        return ws, qs\n",
    "\n",
    "    def compute_objective(self, sols):\n",
    "        ws, qs = self.transform_to_w(sols)\n",
    "\n",
    "        images = self.gen_model.model.synthesis(ws, noise_mode='const')\n",
    "        embeds = self.class_model.embed_image(images.add(1).div(2))\n",
    "    \n",
    "        loss = prompts_dist_loss(embeds, self.obj_targets, spherical_dist_loss).mean(0)\n",
    "        loss = loss + 0.01 * (self.gen_model.q_norm - torch.norm(qs[0])).pow(2)\n",
    "        loss.backward()\n",
    "\n",
    "        value = loss.cpu().detach().numpy()\n",
    "        jacobian = -qs[0].grad.cpu().detach().numpy()\n",
    "        return value, jacobian.flatten()\n",
    "\n",
    "    def compute_measure(self, index, sols):\n",
    "        ws, qs = self.transform_to_w(sols)\n",
    "\n",
    "        images = self.gen_model.model.synthesis(ws, noise_mode='const')\n",
    "        embeds = self.class_model.embed_image(images.add(1).div(2))\n",
    "\n",
    "        measure_targets = self.measures[index]\n",
    "        pos_loss = prompts_dist_loss(embeds, measure_targets[0], cos_sim_loss).mean(0)\n",
    "        neg_loss = prompts_dist_loss(embeds, measure_targets[1], cos_sim_loss).mean(0)\n",
    "        loss = pos_loss - neg_loss\n",
    "        loss.backward()\n",
    "\n",
    "        value = loss.cpu().detach().numpy()\n",
    "        jacobian = qs[0].grad.cpu().detach().numpy()\n",
    "        return value, jacobian.flatten()\n",
    "\n",
    "    def compute_measures(self, sols):\n",
    "    \n",
    "        values = []\n",
    "        jacobian = []\n",
    "        for i in range(len(self.measures)):\n",
    "            value, jac = self.compute_measure(i, sols)\n",
    "            values.append(value)\n",
    "            jacobian.append(jac)\n",
    "\n",
    "        return np.stack(values, axis=0), np.stack(jacobian, axis=0)\n",
    "\n",
    "    def compute_all(self, sols):\n",
    "        with torch.inference_mode():\n",
    "\n",
    "            ws, qs = self.transform_to_w(sols)\n",
    "            qs = torch.stack(qs, dim=0)\n",
    "\n",
    "            images = self.gen_model.model.synthesis(ws, noise_mode='const')\n",
    "            embeds = self.class_model.embed_image(images.add(1).div(2))\n",
    "            \n",
    "            values = []\n",
    "            loss = prompts_dist_loss(embeds, self.obj_targets, spherical_dist_loss).mean(0)\n",
    "            loss = loss + 0.01 * (self.gen_model.q_norm - torch.norm(qs, dim=(1,2))).pow(2)\n",
    "            value = loss.cpu().detach().numpy()\n",
    "            values.append(value)\n",
    "            \n",
    "            for i in range(len(self.measures)):\n",
    "                measure_targets = self.measures[i]\n",
    "                pos_loss = prompts_dist_loss(\n",
    "                        embeds, \n",
    "                        measure_targets[0], \n",
    "                        cos_sim_loss,\n",
    "                    ).mean(0)\n",
    "                neg_loss = prompts_dist_loss(\n",
    "                        embeds, \n",
    "                        measure_targets[1], \n",
    "                        cos_sim_loss\n",
    "                    ).mean(0)\n",
    "                loss = pos_loss - neg_loss\n",
    "                value = loss.cpu().detach().numpy()\n",
    "                values.append(value)\n",
    "\n",
    "        return np.stack(values, axis=0)\n",
    "\n",
    "\n",
    "def transform_obj(objs):\n",
    "    # Remap the objective from minimizing [0, 20] to maximizing [0, 100]\n",
    "    return (20.0-objs)*5.0\n",
    "\n",
    "def create_optimizer(algorithm, classifier, seed):\n",
    "    \"\"\"Creates an optimizer based on the algorithm name.\n",
    "\n",
    "    Args:\n",
    "        algorithm (str): Name of the algorithm passed into sphere_main.\n",
    "        classifier (Classifier): The models for the search.\n",
    "        seed (int): Main seed or the various components.\n",
    "    Returns:\n",
    "        Scheduler: A ribs Scheduler for running the algorithm.\n",
    "    \"\"\"\n",
    "    bounds = [(-0.3, 0.3), (-0.3, 0.3)]\n",
    "    initial_sol = classifier.find_good_start_latent().cpu().detach().numpy()\n",
    "    solution_dim = len(initial_sol)\n",
    "    batch_size = 36\n",
    "    num_emitters = 1\n",
    "    resolution = 200\n",
    "    archive_dims = (resolution, resolution)\n",
    "\n",
    "    # Create archive.\n",
    "    archive = GridArchive(\n",
    "            solution_dim=solution_dim, \n",
    "            dims=archive_dims, \n",
    "            ranges=bounds,\n",
    "            learning_rate=0.02,\n",
    "            threshold_min=0.0,\n",
    "            seed=seed,\n",
    "    )\n",
    "\n",
    "    # Maintain a result archive.\n",
    "    result_archive = GridArchive(solution_dim=solution_dim, dims=archive_dims, ranges=bounds, seed=seed)\n",
    "\n",
    "    # Create emitters. Each emitter needs a different seed, so that they do not\n",
    "    # all do the same thing.\n",
    "    emitter_seeds = [None] * num_emitters if seed is None else list(\n",
    "        range(seed, seed + num_emitters))\n",
    "    emitters = [\n",
    "        EvolutionStrategyEmitter(archive,\n",
    "                         x0=initial_sol,\n",
    "                         sigma0=0.03,\n",
    "                         ranker=\"imp\",\n",
    "                         restart_rule=300,\n",
    "                         batch_size=batch_size,\n",
    "                         seed=s) for s in emitter_seeds\n",
    "    ]\n",
    "\n",
    "    return Scheduler(archive, emitters, result_archive=result_archive)\n",
    "\n",
    "def save_heatmap(archive, heatmap_path):\n",
    "    \"\"\"Saves a heatmap of the archive to the given path.\n",
    "\n",
    "    Args:\n",
    "        archive (GridArchive or CVTArchive): The archive to save.\n",
    "        heatmap_path: Image path for the heatmap.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    grid_archive_heatmap(archive, vmin=0, vmax=100, cmap=\"viridis\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(heatmap_path)\n",
    "    plt.close(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cg6QcVj0v2-n"
   },
   "outputs": [],
   "source": [
    "# Initialization.\n",
    "celebrity='Lopez'\n",
    "outdir='logs'\n",
    "            \n",
    "# Create a shared logging directory for the experiments for this algorithm.\n",
    "s_logdir = os.path.join(outdir, \"cma_mae\")\n",
    "logdir = Path(s_logdir)\n",
    "outdir = Path(outdir)\n",
    "if not outdir.is_dir():\n",
    "    outdir.mkdir()\n",
    "if not logdir.is_dir():\n",
    "    logdir.mkdir()\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "clip_model = CLIP(device=device)\n",
    "gen_model = Generator(device=device)\n",
    "classifier = Classifier(gen_model, clip_model, celebrity_id=celebrity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgG7FiTViJhr"
   },
   "outputs": [],
   "source": [
    "# StyleGAN+CLIP LSI experiments.\n",
    "trials=5\n",
    "init_pop=100\n",
    "itrs=10000\n",
    "log_freq=1\n",
    "log_arch_freq=1000\n",
    "image_monitor=False\n",
    "image_monitor_freq=5\n",
    "seed=None\n",
    "\n",
    "for trial_id in range(trials):\n",
    "    print(\"Running trial\", trial_id)\n",
    "    # Create a directory for this specific trial.\n",
    "    s_logdir = os.path.join(outdir, \"cma_mae\", f\"trial_{trial_id}\")\n",
    "    logdir = Path(s_logdir)\n",
    "    if not logdir.is_dir():\n",
    "        logdir.mkdir()\n",
    "\n",
    "    # Create a directory for logging intermediate images if the monitor is on.\n",
    "    if image_monitor:\n",
    "        image_monitor_freq = max(1, image_monitor_freq)\n",
    "        gen_output_dir = os.path.join('generations')\n",
    "        logdir = Path(gen_output_dir)\n",
    "        if not logdir.is_dir():\n",
    "            logdir.mkdir()\n",
    "        gen_output_dir = os.path.join('generations', f\"trial_{trial_id}\")\n",
    "        logdir = Path(gen_output_dir)\n",
    "        if not logdir.is_dir():\n",
    "            logdir.mkdir()\n",
    "\n",
    "    # Create a new summary file\n",
    "    summary_filename = os.path.join(s_logdir, \"summary.csv\")\n",
    "    if os.path.exists(summary_filename):\n",
    "        os.remove(summary_filename)\n",
    "    with open(summary_filename, 'w') as summary_file:\n",
    "        writer = csv.writer(summary_file)\n",
    "        writer.writerow(['Iteration', 'QD-Score', 'Coverage', 'Maximum', 'Average'])\n",
    "    \n",
    "    scheduler = create_optimizer(\"cma_mae\", classifier, seed)\n",
    "    result_archive = scheduler.result_archive\n",
    "\n",
    "    best = -1000\n",
    "    non_logging_time = 0.0\n",
    "    for itr in tqdm(range(1, itrs + 1)):\n",
    "        itr_start = time.time()\n",
    "\n",
    "        sols = scheduler.ask()\n",
    "\n",
    "        values = classifier.compute_all(sols)\n",
    "        values = np.transpose(values)\n",
    "\n",
    "        objs = values[:,0]\n",
    "        measures = values[:,1:3]\n",
    "\n",
    "        objs = transform_obj(np.array(objs, dtype=np.float32))\n",
    "        measures = np.array(measures, dtype=np.float32)\n",
    "\n",
    "        best_gen = max(objs) \n",
    "        best = max(best, best_gen)\n",
    "\n",
    "        scheduler.tell(objs, measures)\n",
    "\n",
    "        non_logging_time += time.time() - itr_start\n",
    "\n",
    "        print('best', best, best_gen)\n",
    "\n",
    "        if image_monitor and itr % image_monitor_freq == 0:\n",
    "            best_index = np.argmax(objs)\n",
    "            latent_code = sols[best_index]\n",
    "\n",
    "            img = classifier.generate_image(latent_code)\n",
    "            img = tensor_to_pil_img(img)\n",
    "            img.save(os.path.join(gen_output_dir, f'{itr}.png'))\n",
    "\n",
    "        # Save the archive at the given frequency. Always save on the final iteration.\n",
    "        final_itr = itr == itrs\n",
    "        if (itr > 0 and itr % log_arch_freq == 0) or final_itr:\n",
    "            # Save a full archive for analysis.\n",
    "            df = result_archive.as_pandas(include_solutions = final_itr)\n",
    "            df.to_pickle(os.path.join(s_logdir, f\"archive_{itr:08d}.pkl\"))\n",
    "\n",
    "            # Save a heatmap image to observe how the trial is doing.\n",
    "            save_heatmap(result_archive, os.path.join(s_logdir, f\"heatmap_{itr:08d}.png\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
