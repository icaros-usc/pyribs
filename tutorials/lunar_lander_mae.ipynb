{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd0b1868-2cf7-436b-8c9a-28ede7ac7260",
   "metadata": {},
   "source": [
    "# Lunar Lander Upgraded: Migrating from CMA-ME to CMA-MAE\n",
    "\n",
    "In the [previous tutorial](https://docs.pyribs.org/en/latest/tutorials/lunar_lander.html), we showed how to implement the CMA-ME algorithm in pyribs to tackle the lunar lander problem. CMA-ME enabled us to search for a diverse collection of high-performing lunar lander agents, including agents which landed like a space shuttle as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cb4e2d6-50de-4ddf-b12f-9aa1d9766074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"360\" height=\"auto\" controls><source src=\"https://raw.githubusercontent.com/icaros-usc/pyribs/master/docs/_static/imgs/lunar-lander-left.mp4\" type=\"video/mp4\" /></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"<video width=\"360\" height=\"auto\" controls><source src=\"https://raw.githubusercontent.com/icaros-usc/pyribs/master/docs/_static/imgs/lunar-lander-left.mp4\" type=\"video/mp4\" /></video>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93931e1d-d373-4f82-8210-19ae5d2c7c54",
   "metadata": {},
   "source": [
    "Recent work introduced [Covariance Matrix Adaptation MAP-Annealing (CMA-MAE)](https://arxiv.org/abs/2205.10752), an algorithm which builds on and improves CMA-ME. CMA-MAE not only has strong theoretical guarantees; it also empirically outperforms CMA-ME in a variety of domains. In this tutorial, we show how to implement this more advanced algorithm in pyribs.\n",
    "\n",
    "_Below: CMA-MAE vs CMA-ME on the 100-dimensional sphere linear projection benchmark described in [Fontaine 2020](https://arxiv.org/abs/1912.02400). We can see how CMA-MAE does a much better job of populating the archive with high-performing solutions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a1fdd00-3758-4788-b471-d37ec663f2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"720\" height=\"auto\" autoplay muted playsinline loop><source src=\"https://raw.githubusercontent.com/icaros-usc/pyribs/master/docs/_static/imgs/cma-mae-vs-cma-me-imp.mp4\" type=\"video/mp4\" /></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\"\"\"<video width=\"720\" height=\"auto\" autoplay muted playsinline loop><source src=\"https://raw.githubusercontent.com/icaros-usc/pyribs/master/docs/_static/imgs/cma-mae-vs-cma-me-imp.mp4\" type=\"video/mp4\" /></video>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e600c23-d21c-442a-a44e-d61f3205e18d",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "As in the previous tutorial, let's begin by installing and importing the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14520d93-e261-4dc8-8618-5ff78b41b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ribs[visualize] gymnasium[box2d]==0.27.0 \"moviepy>=1.0.0\"\n",
    "\n",
    "# An uninstalled version of decorator is occasionally loaded. This loads the\n",
    "# newly installed version of decorator so that moviepy works properly -- see\n",
    "# https://github.com/Zulko/moviepy/issues/1625\n",
    "import importlib\n",
    "import decorator\n",
    "importlib.reload(decorator)\n",
    "\n",
    "import gymnasium as gym\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d194e7ac-f62c-4bde-a60b-003ccf9ea989",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "\n",
    "We adopt the same lunar lander problem as described in the first lunar lander tutorial. To recap, in this problem, the objective is provided by the lunar lander environment, which rewards the agent for making a smooth landing (albeit not necessarily on the landing pad in the environment). Meanwhile, there are two measures: the $x$-position when the lunar lander first impacts the ground, and the $y$-velocity when the lunar lander first impacts the ground."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66ba4ec1-e12b-42fe-93f9-f53766743cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v2\")\n",
    "seed = 52\n",
    "action_dim = env.action_space.n\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "\n",
    "def simulate(env, model, seed=None):\n",
    "    \"\"\"Simulates the lunar lander model.\n",
    "\n",
    "    Args:\n",
    "        env (gym.Env): A lunar lander environment.\n",
    "        model (np.ndarray): The array of weights for the linear policy. The\n",
    "            weights are passed in as a 1D array and reshaped into a matrix.\n",
    "        seed (int): The seed for the environment.\n",
    "    Returns:\n",
    "        total_reward (float): The reward accrued by the lander throughout its\n",
    "            trajectory.\n",
    "        impact_x_pos (float): The x position of the lander when it touches the\n",
    "            ground for the first time.\n",
    "        impact_y_vel (float): The y velocity of the lander when it touches the\n",
    "            ground for the first time.\n",
    "    \"\"\"\n",
    "    action_dim = env.action_space.n\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    model = model.reshape((action_dim, obs_dim))\n",
    "\n",
    "    total_reward = 0.0\n",
    "    impact_x_pos = None\n",
    "    impact_y_vel = None\n",
    "    all_y_vels = []\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = np.argmax(model @ obs)  # Linear policy.\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        total_reward += reward\n",
    "\n",
    "        # Refer to the definition of state here:\n",
    "        # https://gymnasium.farama.org/environments/box2d/lunar_lander/\n",
    "        x_pos = obs[0]\n",
    "        y_vel = obs[3]\n",
    "        leg0_touch = bool(obs[6])\n",
    "        leg1_touch = bool(obs[7])\n",
    "        all_y_vels.append(y_vel)\n",
    "\n",
    "        # Check if the lunar lander is impacting for the first time.\n",
    "        if impact_x_pos is None and (leg0_touch or leg1_touch):\n",
    "            impact_x_pos = x_pos\n",
    "            impact_y_vel = y_vel\n",
    "\n",
    "    # If the lunar lander did not land, set the x-pos to the one from the final\n",
    "    # timestep, and set the y-vel to the max y-vel (we use min since the lander\n",
    "    # goes down).\n",
    "    if impact_x_pos is None:\n",
    "        impact_x_pos = x_pos\n",
    "        impact_y_vel = min(all_y_vels)\n",
    "\n",
    "    return total_reward, impact_x_pos, impact_y_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59d5dcb7-8169-4bc2-99d2-527435492fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ribs.archives import GridArchive\n",
    "initial_model = np.zeros((action_dim, obs_dim))\n",
    "\n",
    "archive = GridArchive(\n",
    "    solution_dim=initial_model.size,  # Dimensionality of solutions in the archive.\n",
    "    dims=[50, 50],  # 50 cells along each dimension.\n",
    "    ranges=[(-1.0, 1.0), (-3.0, 0.0)],  # (-1, 1) for x-pos and (-3, 0) for y-vel.\n",
    "    qd_score_offset=-300,  # See the note below.\n",
    "    learning_rate=0.01,\n",
    "    threshold_min=-300,\n",
    ")\n",
    "\n",
    "result_archive = GridArchive(\n",
    "    solution_dim=initial_model.size,  # Dimensionality of solutions in the archive.\n",
    "    dims=[50, 50],  # 50 cells along each dimension.\n",
    "    ranges=[(-1.0, 1.0), (-3.0, 0.0)],  # (-1, 1) for x-pos and (-3, 0) for y-vel.\n",
    "    qd_score_offset=-300,  # See the note below.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae7ae6c8-5fbd-46d2-8095-36a36df74fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ribs.emitters import EvolutionStrategyEmitter\n",
    "\n",
    "emitters = [\n",
    "    EvolutionStrategyEmitter(\n",
    "        archive=archive,\n",
    "        x0=initial_model.flatten(),\n",
    "        sigma0=1.0,  # Initial step size.\n",
    "        ranker=\"imp\",\n",
    "        selection_rule=\"mu\",\n",
    "        restart_rule=\"basic\",\n",
    "        batch_size=30,  # If we do not specify a batch size, the emitter will\n",
    "                        # automatically use a batch size equal to the default\n",
    "                        # population size of CMA-ES.\n",
    "    ) for _ in range(5)  # Create 5 separate emitters.\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6138a5b2-5313-4d17-9a88-b6720eafcaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ribs.schedulers import Scheduler\n",
    "\n",
    "scheduler = Scheduler(archive, emitters, result_archive=result_archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "377e4229-f4ee-4db8-9934-b785061c172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 25 itrs completed after 479.12s\n",
      "  - Size: 623\n",
      "  - Coverage: 0.2492\n",
      "  - QD Score: 140586.6048369406\n",
      "  - Max Score: 294.2905210971211\n",
      "> 50 itrs completed after 1720.96s\n",
      "  - Size: 796\n",
      "  - Coverage: 0.3184\n",
      "  - QD Score: 188022.81781493407\n",
      "  - Max Score: 310.3286522183843\n",
      "> 75 itrs completed after 2969.42s\n",
      "  - Size: 886\n",
      "  - Coverage: 0.3544\n",
      "  - QD Score: 236476.54234859342\n",
      "  - Max Score: 314.951865182828\n",
      "> 100 itrs completed after 4609.08s\n",
      "  - Size: 946\n",
      "  - Coverage: 0.3784\n",
      "  - QD Score: 265138.7602530137\n",
      "  - Max Score: 314.951865182828\n",
      "> 125 itrs completed after 5820.52s\n",
      "  - Size: 980\n",
      "  - Coverage: 0.392\n",
      "  - QD Score: 277482.19482221134\n",
      "  - Max Score: 314.951865182828\n",
      "> 150 itrs completed after 6952.63s\n",
      "  - Size: 1005\n",
      "  - Coverage: 0.402\n",
      "  - QD Score: 296550.4362170957\n",
      "  - Max Score: 314.951865182828\n",
      "> 175 itrs completed after 7978.13s\n",
      "  - Size: 1032\n",
      "  - Coverage: 0.4128\n",
      "  - QD Score: 309914.090188502\n",
      "  - Max Score: 314.951865182828\n",
      "> 200 itrs completed after 8973.91s\n",
      "  - Size: 1073\n",
      "  - Coverage: 0.4292\n",
      "  - QD Score: 331375.84004399535\n",
      "  - Max Score: 317.98823809376927\n",
      "> 225 itrs completed after 9701.58s\n",
      "  - Size: 1100\n",
      "  - Coverage: 0.44\n",
      "  - QD Score: 336723.8185548895\n",
      "  - Max Score: 317.98823809376927\n",
      "> 250 itrs completed after 10828.07s\n",
      "  - Size: 1113\n",
      "  - Coverage: 0.4452\n",
      "  - QD Score: 346249.1590358822\n",
      "  - Max Score: 317.98823809376927\n",
      "> 275 itrs completed after 11572.89s\n",
      "  - Size: 1118\n",
      "  - Coverage: 0.4472\n",
      "  - QD Score: 350160.3290194687\n",
      "  - Max Score: 317.98823809376927\n",
      "> 300 itrs completed after 12411.71s\n",
      "  - Size: 1121\n",
      "  - Coverage: 0.4484\n",
      "  - QD Score: 353458.0424543469\n",
      "  - Max Score: 318.4488722863921\n",
      "> 325 itrs completed after 13294.70s\n",
      "  - Size: 1123\n",
      "  - Coverage: 0.4492\n",
      "  - QD Score: 346864.54935401515\n",
      "  - Max Score: 318.4488722863921\n",
      "> 350 itrs completed after 14230.71s\n",
      "  - Size: 1123\n",
      "  - Coverage: 0.4492\n",
      "  - QD Score: 346106.8196391532\n",
      "  - Max Score: 318.4488722863921\n",
      "> 375 itrs completed after 15060.01s\n",
      "  - Size: 1124\n",
      "  - Coverage: 0.4496\n",
      "  - QD Score: 352499.22794899094\n",
      "  - Max Score: 318.4488722863921\n",
      "> 400 itrs completed after 15648.35s\n",
      "  - Size: 1127\n",
      "  - Coverage: 0.4508\n",
      "  - QD Score: 355731.9214607087\n",
      "  - Max Score: 318.4488722863921\n",
      "> 425 itrs completed after 16305.20s\n",
      "  - Size: 1127\n",
      "  - Coverage: 0.4508\n",
      "  - QD Score: 353489.59216873476\n",
      "  - Max Score: 318.4488722863921\n",
      "> 450 itrs completed after 17235.06s\n",
      "  - Size: 1127\n",
      "  - Coverage: 0.4508\n",
      "  - QD Score: 350257.50498123636\n",
      "  - Max Score: 318.4488722863921\n",
      "> 475 itrs completed after 18090.82s\n",
      "  - Size: 1127\n",
      "  - Coverage: 0.4508\n",
      "  - QD Score: 353133.8690842462\n",
      "  - Max Score: 318.4488722863921\n",
      "> 500 itrs completed after 18757.96s\n",
      "  - Size: 1127\n",
      "  - Coverage: 0.4508\n",
      "  - QD Score: 352203.61038661026\n",
      "  - Max Score: 318.4488722863921\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "total_itrs = 500\n",
    "\n",
    "for itr in range(1, total_itrs + 1):\n",
    "    # Request models from the scheduler.\n",
    "    sols = scheduler.ask()\n",
    "\n",
    "    # Evaluate the models and record the objectives and measuress.\n",
    "    objs, meas = [], []\n",
    "    for model in sols:\n",
    "        obj, impact_x_pos, impact_y_vel = simulate(env, model, seed)\n",
    "        objs.append(obj)\n",
    "        meas.append([impact_x_pos, impact_y_vel])\n",
    "\n",
    "    # Send the results back to the scheduler.\n",
    "    scheduler.tell(objs, meas)\n",
    "\n",
    "    # Logging.\n",
    "    if itr % 25 == 0:\n",
    "        print(f\"> {itr} itrs completed after {time.time() - start_time:.2f}s\")\n",
    "        print(f\"  - Size: {archive.stats.num_elites}\")    # Number of elites in the archive.\n",
    "        print(f\"  - Coverage: {archive.stats.coverage}\")  # Proportion of archive cells which have an elite.\n",
    "        print(f\"  - QD Score: {archive.stats.qd_score}\")  # QD score, i.e. sum of objective values of all elites in the archive.\n",
    "                                                          # Accounts for qd_score_offset as described in the GridArchive section.\n",
    "        print(f\"  - Max Score: {archive.stats.obj_max}\")  # Maximum objective value in the archive."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
