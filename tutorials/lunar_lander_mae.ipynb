{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd0b1868-2cf7-436b-8c9a-28ede7ac7260",
   "metadata": {},
   "source": [
    "# Lunar Lander Upgraded: Migrating from CMA-ME to CMA-MAE\n",
    "\n",
    "In the [previous tutorial](https://docs.pyribs.org/en/stable/tutorials/lunar_lander.html), we showed how to implement the CMA-ME algorithm in pyribs. Recent work introduced [Covariance Matrix Adaptation MAP-Annealing (CMA-MAE)](https://arxiv.org/abs/2205.10752), an algorithm which builds on and improves CMA-ME. CMA-MAE not only has strong theoretical guarantees; it also empirically outperforms CMA-ME in a variety of domains. In this tutorial, we show how to implement this more advanced algorithm in pyribs.\n",
    "\n",
    "TODO (Front cover image, perhaps a video showing CMA-ME vs CMA-MAE on sphere, also show lunar lander in an image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e600c23-d21c-442a-a44e-d61f3205e18d",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "As in the previous tutorial, let's begin by installing and importing the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14520d93-e261-4dc8-8618-5ff78b41b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ribs[visualize] gymnasium[box2d]==0.27.0 \"moviepy>=1.0.0\"\n",
    "\n",
    "# An uninstalled version of decorator is occasionally loaded. This loads the\n",
    "# newly installed version of decorator so that moviepy works properly -- see\n",
    "# https://github.com/Zulko/moviepy/issues/1625\n",
    "import importlib\n",
    "import decorator\n",
    "importlib.reload(decorator)\n",
    "\n",
    "import gymnasium as gym\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d194e7ac-f62c-4bde-a60b-003ccf9ea989",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "\n",
    "We adopt the same lunar lander problem as described in the first lunar lander tutorial. To recap, in this problem, the objective is provided by the lunar lander environment, which rewards the agent for making a smooth landing (albeit not necessarily on the landing pad in the environment). Meanwhile, there are two measures: the $x$-position when the lunar lander first impacts the ground, and the $y$-velocity when the lunar lander first impacts the ground."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ba4ec1-e12b-42fe-93f9-f53766743cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v2\")\n",
    "seed = 52\n",
    "action_dim = env.action_space.n\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "\n",
    "def simulate(env, model, seed=None):\n",
    "    \"\"\"Simulates the lunar lander model.\n",
    "\n",
    "    Args:\n",
    "        env (gym.Env): A lunar lander environment.\n",
    "        model (np.ndarray): The array of weights for the linear policy. The\n",
    "            weights are passed in as a 1D array and reshaped into a matrix.\n",
    "        seed (int): The seed for the environment.\n",
    "    Returns:\n",
    "        total_reward (float): The reward accrued by the lander throughout its\n",
    "            trajectory.\n",
    "        impact_x_pos (float): The x position of the lander when it touches the\n",
    "            ground for the first time.\n",
    "        impact_y_vel (float): The y velocity of the lander when it touches the\n",
    "            ground for the first time.\n",
    "    \"\"\"\n",
    "    action_dim = env.action_space.n\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    model = model.reshape((action_dim, obs_dim))\n",
    "\n",
    "    total_reward = 0.0\n",
    "    impact_x_pos = None\n",
    "    impact_y_vel = None\n",
    "    all_y_vels = []\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = np.argmax(model @ obs)  # Linear policy.\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        total_reward += reward\n",
    "\n",
    "        # Refer to the definition of state here:\n",
    "        # https://gymnasium.farama.org/environments/box2d/lunar_lander/\n",
    "        x_pos = obs[0]\n",
    "        y_vel = obs[3]\n",
    "        leg0_touch = bool(obs[6])\n",
    "        leg1_touch = bool(obs[7])\n",
    "        all_y_vels.append(y_vel)\n",
    "\n",
    "        # Check if the lunar lander is impacting for the first time.\n",
    "        if impact_x_pos is None and (leg0_touch or leg1_touch):\n",
    "            impact_x_pos = x_pos\n",
    "            impact_y_vel = y_vel\n",
    "\n",
    "    # If the lunar lander did not land, set the x-pos to the one from the final\n",
    "    # timestep, and set the y-vel to the max y-vel (we use min since the lander\n",
    "    # goes down).\n",
    "    if impact_x_pos is None:\n",
    "        impact_x_pos = x_pos\n",
    "        impact_y_vel = min(all_y_vels)\n",
    "\n",
    "    return total_reward, impact_x_pos, impact_y_vel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
